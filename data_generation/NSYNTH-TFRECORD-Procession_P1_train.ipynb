{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[tfrecord tutorial from TensorFlow](https://www.tensorflow.org/tutorials/load_data/tfrecord)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import tensorflow_datasets as tfds\n",
    "import os\n",
    "#from tensorflow_datasets.audio import nsynth\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from google.protobuf.json_format import MessageToJson"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PATH_TRAIN = r\"E:\\nsynth233\\2.3.3\\train\"\n",
    "PATH_VALID = r\"E:\\nsynth233\\2.3.3\\valid\"\n",
    "TFRECORD_FILES_TRAIN = os.listdir(PATH_TRAIN )\n",
    "#TFRECORD_FILES_VALIDATION = os.listdir(PATH_VALID)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nsynth._AUDIO_RATE\n",
    "nsynth._DESCRIPTION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nsynth._SPLITS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inspect single TFR example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## gansynth subset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(r\"E:\\nsynth233\\2.3.3\\train\\nsynth-train.tfrecord-00000-of-00128\")\n",
    "for d in dataset.take(1):\n",
    "    ex = tf.train.SequenceExample()\n",
    "    ex2 = ex.ParseFromString(d.numpy())\n",
    "    gan_ex = json.loads(MessageToJson(ex))\n",
    "    #print(m['features']['feature'].keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex3 = ex.context.feature\n",
    "ex3[\"audio\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(gan_ex['context']['feature'].keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gan_ex['context']['feature']['f0/hz']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gan_ex['context']['feature']['f0/confidence']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gan_ex['context']['feature']['loudness/db']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gan_ex['context']['feature']['f0/midi']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gan_ex['context'][\"feature\"][\"audio\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3.3 full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(r\"datasets_nsynth_full_2.3.3_nsynth-test (1).tfrecord-00000-of-00008\")\n",
    "for d in dataset.take(1):\n",
    "    ex = tf.train.SequenceExample()\n",
    "    ex2 = ex.ParseFromString(d.numpy())\n",
    "    m = json.loads(MessageToJson(ex))\n",
    "    #print(m['features']['feature'].keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex3 = ex.context.feature\n",
    "ex3[\"audio\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(m['context']['feature'].keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m['context']['feature']['loudness/db']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m['context'][\"feature\"][\"audio\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read and Write TFR Files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "take some random example to write"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files_to_write = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for raw_record in dataset.take(2):\n",
    "    files_to_write.append(raw_record)\n",
    "    example_write = tf.train.SequenceExample()\n",
    "    write_to_disk = raw_record\n",
    "\n",
    "#print(write_to_disk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(other way to represent it)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) add the tensor file to tf.data.Dataset (more could be added)\n",
    "2) write the file to some filename (it should now be visible in your folder structure)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename_example = \"nsynth-valid-nico.tfrecord-111-of-32\"\n",
    "for idx,file in  enumerate(files_to_write):\n",
    "    dataset_write = tf.data.Dataset.from_tensors(file)\n",
    "    writer = tf.data.experimental.TFRecordWriter(filename_example)\n",
    "    writer.write(dataset_write)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_write = tf.data.Dataset.from_tensor_slices(files_to_write)\n",
    "writer = tf.data.experimental.TFRecordWriter(filename_example )\n",
    "writer.write(dataset_write)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "raw_dataset_read = tf.data.TFRecordDataset(filename_example)\n",
    "print(raw_dataset_read)\n",
    "for raw_record_nico in raw_dataset_read.take(2):\n",
    "    read_from_disk = raw_record_nico\n",
    "    #print(read_from_disk)\n",
    "    example_read = tf.train.SequenceExample()\n",
    "    print(example_read.ParseFromString(read_from_disk.numpy()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for raw_record in raw_dataset_read.take(2):\n",
    "\n",
    "    # extract instrument family\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    example_JSON = json.loads(MessageToJson(example))\n",
    "    instrument_family = example_JSON[\"context\"][\"feature\"]['instrument/family']['int64List']['value']\n",
    "\n",
    "    #['feature']['instrument/family']['int64List']['value']\n",
    "    print(instrument_family)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "filename = f\"nsynth-valid-nico.tfrecord-00-of-32\"\n",
    "dataset_write = tf.data.Dataset.from_tensor_slices(files_to_write)\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(dataset_write)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "read the same file back in and check if it is really the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_read.ParseFromString(read_from_disk.numpy()) == example_write.ParseFromString(write_to_disk.numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "so the two files represent exactly the same object !"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sorting by instrument family"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation Files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_samples_info = []\n",
    "original_order_instr_fam = []\n",
    "for group_index,data_group in enumerate(TFRECORD_FILES_VALIDATION):\n",
    "  data_group = tf.data.TFRecordDataset(PATH_VALID + \"/\" + data_group)\n",
    "  print(group_index)\n",
    "  for raw_record in data_group:\n",
    "    if group_index<=20:\n",
    "      parsed_record = tf.train.SequenceExample()\n",
    "      parsed_record.ParseFromString(raw_record.numpy())\n",
    "      # convert raw uninformative string to JSON\n",
    "      for_inst_fam = json.loads(MessageToJson(ex))\n",
    "      instrument_family = for_inst_fam['context']['feature']['instrument/family']['int64List']['value']\n",
    "      #instrument_type = parsed_record.features.feature['instrument_family_str'].bytes_list.value[0]\n",
    "      original_order_instr_fam.append(instrument_family)\n",
    "      processed_samples_info.append([group_index,raw_record,instrument_family,parsed_record])\n",
    "      #print(instrument_type)\n",
    "    else:\n",
    "        print(\"finished\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex = parsed_record\n",
    "m = json.loads(MessageToJson(ex))\n",
    "\n",
    "print(m['context']['feature'].keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(m['context']['feature']['instrument/family']['int64List']['value'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "unique_fam_values = set([fam[0] for fam in original_order_instr_fam])\n",
    "print(unique_fam_values)\n",
    "# looks like all validation samples belong to instr family 5, what about instr label ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "instrument_families = [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\",\"mallet\",\"organ\",\"reed\",\"string\",\"synth_lead\",\"vocal\"]\n",
    "sorted_by_instr_val = {\n",
    "\"bass\": [],\n",
    "\"brass\": [],\n",
    "\"flute\" : [],\n",
    "\"guitar\" : [],\n",
    "\"keyboard\" : [],\n",
    "\"mallet\" : [],\n",
    "\"organ\" : [],\n",
    "\"reed\" : [],\n",
    "\"string\" : [],\n",
    "\"synth_lead\" : [],\n",
    "\"vocal\" : []\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def sort_by_instrument(data, instr_dict):\n",
    "    for sample in data:\n",
    "      instr_fam = sample[2]\n",
    "      print(instr_fam)\n",
    "      instr_dict[instrument_families[int(instr_fam[0])]].append(sample)\n",
    "    return instr_dict\n",
    "\n",
    "\n",
    "sorted_by_instr_val  = sort_by_instrument(processed_samples_info, sorted_by_instr_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_by_instr_val[\"guitar\"][3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "guitar = sorted_by_instr_val[\"guitar\"][3]\n",
    "#guitar\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    \"bass\": [],\n",
    "    \"brass\": [],\n",
    "    \"flute\" : [],\n",
    "    \"guitar\" : [[0,\"tensor\",\"type\",\"parsed\"]],\n",
    "    \"keyboard\" : [],\n",
    "    \"mallet\" : [],\n",
    "    \"organ\" : [],\n",
    "    \"reed\" : [],\n",
    "    \"string\" : [],\n",
    "    \"synth_lead\" : [],\n",
    "    \"vocal\" : []\n",
    "}\n",
    "\n",
    "test_guitar = test_dict[\"guitar\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_guitar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# same as last one (todo ?)\n",
    "def sort_raw_records_by_instrument(data):\n",
    "    instrument_families = [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\",\"mallet\",\"organ\",\"reed\",\"string\",\"synth_lead\",\"vocal\"]\n",
    "    instr_dict_train = {\n",
    "        \"bass\": [],\n",
    "        \"brass\": [],\n",
    "        \"flute\" : [],\n",
    "        \"guitar\" : [],\n",
    "        \"keyboard\" : [],\n",
    "        \"mallet\" : [],\n",
    "        \"organ\" : [],\n",
    "        \"reed\" : [],\n",
    "        \"string\" : [],\n",
    "        \"synth_lead\" : [],\n",
    "        \"vocal\" : []\n",
    "    }\n",
    "    for sample in data:\n",
    "      instr_fam = sample[1]\n",
    "      #print(instr_fam)\n",
    "      instr_dict_train[instrument_families[int(instr_fam[0])]].append(sample[0])\n",
    "    return instr_dict_train\n",
    "\n",
    "def writeTFRTrainFiles(instr_dict_train,sort_round):\n",
    "    for key,instr_values in instr_dict_train.items():\n",
    "        if instr_values:\n",
    "            filename_train = f\"{str(sort_round)}-train-{str(key)}-nsynth-subset-train.tfrecord-{str(sort_round)}-label-{str(key)}\"\n",
    "            dataset_write = tf.data.Dataset.from_tensor_slices(instr_values)\n",
    "            writer = tf.data.experimental.TFRecordWriter(filename_train)\n",
    "            writer.write(dataset_write)\n",
    "        else:\n",
    "            print(key,\" has no instrument values for sort round \",sort_round)\n",
    "    return None\n",
    "\n",
    "#sorted_by_instr_train  = sort_raw_records_by_instrument(processed_samples_info_train, sorted_by_instr_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "synth_lead  has no instrument values for sort round  2\n",
      "round 2 finished\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "synth_lead  has no instrument values for sort round  3\n",
      "round 3 finished\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "synth_lead  has no instrument values for sort round  4\n",
      "round 4 finished\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "synth_lead  has no instrument values for sort round  5\n",
      "round 5 finished\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "upper = 20\n",
    "lower = -1\n",
    "\n",
    "#sort_round = 0,1\n",
    "sort_round = 2\n",
    "processed_samples_info_train = []\n",
    "\n",
    "STARTPOSITION = 38\n",
    "\n",
    "for source_group_index,file_in_name in enumerate(TFRECORD_FILES_TRAIN[STARTPOSITION:]):\n",
    "  data_group_train = tf.data.TFRecordDataset(PATH_TRAIN + \"/\" + file_in_name)\n",
    "  #original_order_instr_fam_train = []\n",
    "  if lower < source_group_index < upper: # adjusts per round (>= act / <= act+20)\n",
    "      print(source_group_index)\n",
    "      for raw_record in data_group_train:\n",
    "          parsed_record = tf.train.SequenceExample()\n",
    "          parsed_record.ParseFromString(raw_record.numpy())\n",
    "          # convert raw uninformative string to JSON and extract relevant features\n",
    "          processed = json.loads(MessageToJson(parsed_record))\n",
    "          instrument_family = processed['context']['feature']['instrument/family']['int64List']['value']\n",
    "          #instrument_label = processed['context']['feature']['instrument/label']\n",
    "          #f0_hz = processed['context']['feature']['f0/hz']\n",
    "          #f0_confidence = processed['context']['feature']['f0/confidence']\n",
    "          #loudness_decibel = processed['context']['feature']['loudness/db']\n",
    "          #audio = processed['context'][\"feature\"][\"audio\"]\n",
    "          #instrument_type = parsed_record.features.feature['instrument_family_str'].bytes_list.value[0]\n",
    "          #original_order_instr_fam_train.append((instrument_family,instrument_label))\n",
    "          processed_samples_info_train.append([raw_record,instrument_family])\n",
    "  else:\n",
    "      # write files to disk and clean memory\n",
    "      upper +=20\n",
    "      lower +=20\n",
    "      instr_dict_train = sort_raw_records_by_instrument(processed_samples_info_train)\n",
    "      writeTFRTrainFiles(instr_dict_train, sort_round)\n",
    "      del instr_dict_train\n",
    "      del processed_samples_info_train\n",
    "      print(f\"round {sort_round} finished\")\n",
    "      sort_round += 1\n",
    "      \n",
    "      # continue\n",
    "      for raw_record in data_group_train:\n",
    "          parsed_record = tf.train.SequenceExample()\n",
    "          parsed_record.ParseFromString(raw_record.numpy())\n",
    "          processed = json.loads(MessageToJson(parsed_record))\n",
    "          instrument_family = processed['context']['feature']['instrument/family']['int64List']['value']\n",
    "          processed_samples_info_train = []\n",
    "          processed_samples_info_train.append((raw_record,instrument_family))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ex = parsed_record\n",
    "m = json.loads(MessageToJson(ex))\n",
    "\n",
    "print(m['context']['feature'].keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(m['context']['feature']['instrument/family']['int64List']['value'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "unique_fam_values = set([fam[0] for fam in original_order_instr_fam])\n",
    "print(unique_fam_values)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
