{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digwit678/DIGCREAT_AUDIO_PROCESSION/blob/main/ddsp/colab/tutorials/3_training_string_prediction_mallet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpJd3dlOCStH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/main/ddsp/colab/tutorials/3_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "\n",
        "##### Copyright 2021 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VNhgka4UKNjf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFIqwYGbZ-df"
      },
      "source": [
        "# DDSP Training\n",
        "\n",
        "This notebook demonstrates the libraries in [https://github.com/magenta/ddsp/tree/master/ddsp/training](https://github.com/magenta/ddsp/tree/master/ddsp/training). It is a simple example, overfitting a single audio sample, for educational purposes. \n",
        "\n",
        "_For a full training pipeline please use [ddsp/training/ddsp_run.py](https://github.com/magenta/ddsp/blob/main/ddsp/training/README.md#train-1) as in the [train_autoencoder.ipynb](https://github.com/magenta/ddsp/blob/main/ddsp/colab/demos/train_autoencoder.ipynb)_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "both",
        "id": "S_jXCnwZ2QYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e40c30-887c-4219-871a-545020273205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# Install and import dependencies\n",
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp\n",
        "\n",
        "# Ignore a bunch of deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "\n",
        "import ddsp\n",
        "from ddsp.training import (data, decoders, encoders, models, preprocessing, \n",
        "                           train_util, trainers)\n",
        "from ddsp.colab.colab_utils import play, specplot, DEFAULT_SAMPLE_RATE\n",
        "import gin\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khYj8yiMDxGL"
      },
      "source": [
        "# Get a batch of data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVjqNH1R535M",
        "outputId": "e5842107-680c-4641-ad04-ce1cbbd4438d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from absl import logging\n",
        "from ddsp.spectral_ops import CREPE_FRAME_SIZE\n",
        "from ddsp.spectral_ops import CREPE_SAMPLE_RATE\n",
        "from ddsp.spectral_ops import get_framed_lengths\n",
        "import gin\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "class DataProvider(object):\n",
        "  \"\"\"Base class for returning a dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, sample_rate, frame_rate):\n",
        "    \"\"\"DataProvider constructor.\n",
        "    Args:\n",
        "      sample_rate: Sample rate of audio in the dataset.\n",
        "      frame_rate: Frame rate of features in the dataset.\n",
        "    \"\"\"\n",
        "    self._sample_rate = sample_rate\n",
        "    self._frame_rate = frame_rate\n",
        "\n",
        "  @property\n",
        "  def sample_rate(self):\n",
        "    \"\"\"Return dataset sample rate, must be defined in the constructor.\"\"\"\n",
        "    return self._sample_rate\n",
        "\n",
        "  @property\n",
        "  def frame_rate(self):\n",
        "    \"\"\"Return dataset feature frame rate, must be defined in the constructor.\"\"\"\n",
        "    return self._frame_rate\n",
        "\n",
        "  def get_dataset(self, shuffle):\n",
        "    \"\"\"A method that returns a tf.data.Dataset.\"\"\"\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def get_batch(self,\n",
        "                batch_size,\n",
        "                shuffle=True,\n",
        "                repeats=-1,\n",
        "                drop_remainder=True):\n",
        "    \"\"\"Read dataset.\n",
        "    Args:\n",
        "      batch_size: Size of batch.\n",
        "      shuffle: Whether to shuffle the examples.\n",
        "      repeats: Number of times to repeat dataset. -1 for endless repeats.\n",
        "      drop_remainder: Whether the last batch should be dropped.\n",
        "    Returns:\n",
        "      A batched tf.data.Dataset.\n",
        "    \"\"\"\n",
        "    dataset = self.get_dataset(shuffle)\n",
        "    dataset = dataset.repeat(repeats)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
        "    dataset = dataset.prefetch(buffer_size=_AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "class TFRecordProvider(DataProvider):\n",
        "  \"\"\"Class for reading TFRecords and returning a dataset.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               centered=False):\n",
        "    \"\"\"RecordProvider constructor.\"\"\"\n",
        "    super().__init__(sample_rate, frame_rate)\n",
        "    self._file_pattern = file_pattern or self.default_file_pattern\n",
        "    self._audio_length = example_secs * sample_rate\n",
        "    self._audio_16k_length = example_secs * CREPE_SAMPLE_RATE\n",
        "    self._feature_length = self.get_feature_length(centered)\n",
        "\n",
        "\n",
        "  def get_feature_length(self, centered):\n",
        "    \"\"\"Take into account center padding to get number of frames.\"\"\"\n",
        "    # Number of frames is independent of frame size for \"center/same\" padding.\n",
        "    hop_size = CREPE_SAMPLE_RATE / self.frame_rate\n",
        "    padding = 'center' if centered else 'same'\n",
        "    return get_framed_lengths(\n",
        "        self._audio_16k_length, CREPE_FRAME_SIZE, hop_size, padding)[0]\n",
        "\n",
        "  @property\n",
        "  def default_file_pattern(self):\n",
        "    \"\"\"Used if file_pattern is not provided to constructor.\"\"\"\n",
        "    raise NotImplementedError(\n",
        "        'You must pass a \"file_pattern\" argument to the constructor or '\n",
        "        'choose a FileDataProvider with a default_file_pattern.')\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    \"\"\"Read dataset.\n",
        "    Args:\n",
        "      shuffle: Whether to shuffle the files.\n",
        "    Returns:\n",
        "      dataset: A tf.dataset that reads from the TFRecord.\n",
        "    \"\"\"\n",
        "    def parse_tfexample(record):\n",
        "      return tf.io.parse_single_example(record, self.features_dict)\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=tf.data.TFRecordDataset,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=_AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample, num_parallel_calls=_AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    \"\"\"Dictionary of features to read from dataset.\"\"\"\n",
        "    return {\n",
        "        'audio':\n",
        "            tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "        'f0/hz':\n",
        "            tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "        'f0/confidence':\n",
        "            tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "        'loudness/db':\n",
        "            tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "    }"
      ],
      "metadata": {
        "id": "0c96yljr7ueM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IzzaWKxVkYms",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "6d0c9fe1-0193-4f38-e8fe-cd9fbe3f05e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_1\"> </div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x442.347 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get a single example from NSynth.\n",
        "# Takes a few seconds to load from GCS.\n",
        "import glob\n",
        "\n",
        "_AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "filenames_full = glob.glob(\"/content/drive/MyDrive/NSYNTH_GAN/string/train/*.tfrecord\")\n",
        "data_provider = TFRecordProvider(\n",
        "    \"/content/drive/MyDrive/NSYNTH_GAN/string/train/*.tfrecord\"\n",
        ")\n",
        "filenames_full_2 = glob.glob(\"/content/drive/MyDrive/NSYNTH_GAN/mallet/train/*.tfrecord\")\n",
        "data_provider_2 = TFRecordProvider(\n",
        "    \"/content/drive/MyDrive/NSYNTH_GAN/mallet/train/*.tfrecord\"\n",
        ")\n",
        "\n",
        "dataset = data_provider.get_batch(batch_size=1, shuffle=False).take(1).repeat()\n",
        "dataset2 = data_provider_2.get_batch(batch_size=1, shuffle=False).take(1)\n",
        "batch = next(iter(dataset2))\n",
        "audio = batch['audio']\n",
        "n_samples = audio.shape[1]\n",
        "\n",
        "specplot(audio)\n",
        "play(audio)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#type(dataset)"
      ],
      "metadata": {
        "id": "kaXTpLm9_X6n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acGO0ifg0I3k"
      },
      "source": [
        "# Get a distribution strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2022 The DDSP Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Library of Trainer objects that define traning step and wrap optimizer.\"\"\"\n",
        "\n",
        "import time\n",
        "\n",
        "from absl import logging\n",
        "from ddsp.training import train_util\n",
        "import gin\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "gin.enter_interactive_mode()\n",
        "\n",
        "@gin.configurable\n",
        "\n",
        "class Trainer2(object):\n",
        "  \"\"\"Class to bind an optimizer, model, strategy, and training step function.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               model,\n",
        "               strategy,\n",
        "               checkpoints_to_keep=100,\n",
        "               learning_rate=0.001,\n",
        "               lr_decay_steps=10000,\n",
        "               lr_decay_rate=0.98,\n",
        "               grad_clip_norm=3.0,\n",
        "               restore_keys=None):\n",
        "    \"\"\"Constructor.\n",
        "\n",
        "    Args:\n",
        "      model: Model to train.\n",
        "      strategy: A distribution strategy.\n",
        "      checkpoints_to_keep: Max number of checkpoints before deleting oldest.\n",
        "      learning_rate: Scalar initial learning rate.\n",
        "      lr_decay_steps: Exponential decay timescale.\n",
        "      lr_decay_rate: Exponential decay magnitude.\n",
        "      grad_clip_norm: Norm level by which to clip gradients.\n",
        "      restore_keys: List of names of model properties to restore. If no keys are\n",
        "        passed, restore the whole model.\n",
        "    \"\"\"\n",
        "    self.model = model\n",
        "    self.strategy = strategy\n",
        "    self.checkpoints_to_keep = checkpoints_to_keep\n",
        "    self.grad_clip_norm = grad_clip_norm\n",
        "    self.restore_keys = restore_keys\n",
        "\n",
        "    # Create an optimizer.\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=learning_rate,\n",
        "        decay_steps=lr_decay_steps,\n",
        "        decay_rate=lr_decay_rate)\n",
        "\n",
        "    with self.strategy.scope():\n",
        "      self.optimizer = tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "  def get_checkpoint(self, model=None):\n",
        "    \"\"\"Model arg can also be a tf.train.Checkpoint(**dict(submodules)).\"\"\"\n",
        "    model = model or self.model  # Default to full model.\n",
        "    return tf.train.Checkpoint(model=model, optimizer=self.optimizer)\n",
        "\n",
        "  def save(self, save_dir):\n",
        "    \"\"\"Saves model and optimizer to a checkpoint.\"\"\"\n",
        "    # Saving weights in checkpoint format because saved_model requires\n",
        "    # handling variable batch size, which some synths and effects can't.\n",
        "    start_time = time.time()\n",
        "    checkpoint = self.get_checkpoint()\n",
        "    manager = tf.train.CheckpointManager(\n",
        "        checkpoint, directory=save_dir, max_to_keep=self.checkpoints_to_keep)\n",
        "    step = self.step.numpy()\n",
        "    manager.save(checkpoint_number=step)\n",
        "    logging.info('Saved checkpoint to %s at step %s', save_dir, step)\n",
        "    logging.info('Saving model took %.1f seconds', time.time() - start_time)\n",
        "\n",
        "  def restore(self, checkpoint_path, restore_keys=None):\n",
        "    \"\"\"Restore model and optimizer from a checkpoint if it exists.\n",
        "\n",
        "    Args:\n",
        "      checkpoint_path: Path to checkpoint file or directory.\n",
        "      restore_keys: Optional list of strings for submodules to restore.\n",
        "\n",
        "    Raises:\n",
        "      FileNotFoundError: If no checkpoint is found.\n",
        "    \"\"\"\n",
        "    logging.info('Restoring from checkpoint...')\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Prefer function args over object properties.\n",
        "    restore_keys = restore_keys or self.restore_keys\n",
        "    if restore_keys is None:\n",
        "      # If no keys are passed, restore the whole model.\n",
        "      model = self.model\n",
        "      logging.info('Trainer restoring the full model')\n",
        "    else:\n",
        "      # Restore only sub-modules by building a new subgraph.\n",
        "      restore_dict = {k: getattr(self.model, k) for k in restore_keys}\n",
        "      model = tf.train.Checkpoint(**restore_dict)\n",
        "\n",
        "      logging.info('Trainer restoring model subcomponents:')\n",
        "      for k, v in restore_dict.items():\n",
        "        log_str = 'Restoring {}: {}'.format(k, v)\n",
        "        logging.info(log_str)\n",
        "\n",
        "    # Restore from latest checkpoint.\n",
        "    checkpoint = self.get_checkpoint(model)\n",
        "    latest_checkpoint = train_util.get_latest_checkpoint(checkpoint_path)\n",
        "    # checkpoint.restore must be within a strategy.scope() so that optimizer\n",
        "    # slot variables are mirrored.\n",
        "    with self.strategy.scope():\n",
        "      if restore_keys is None:\n",
        "        checkpoint.restore(latest_checkpoint)\n",
        "      else:\n",
        "        checkpoint.restore(latest_checkpoint).expect_partial()\n",
        "      logging.info('Loaded checkpoint %s', latest_checkpoint)\n",
        "    logging.info('Loading model took %.1f seconds', time.time() - start_time)\n",
        "\n",
        "  @property\n",
        "  def step(self):\n",
        "    \"\"\"The number of training steps completed.\"\"\"\n",
        "    return self.optimizer.iterations\n",
        "\n",
        "  def psum(self, x, axis=None):\n",
        "    \"\"\"Sum across processors.\"\"\"\n",
        "    return self.strategy.reduce(tf.distribute.ReduceOp.SUM, x, axis=axis)\n",
        "\n",
        "  def run(self, fn, *args, **kwargs):\n",
        "    \"\"\"Distribute and run function on processors.\"\"\"\n",
        "    return self.strategy.run(fn, args=args, kwargs=kwargs)\n",
        "\n",
        "  def build(self, batch):\n",
        "    \"\"\"Build the model by running a distributed batch through it.\"\"\"\n",
        "    logging.info('Building the model...')\n",
        "    #batch = rename_features(batch)\n",
        "    _ = self.run(tf.function(self.model.__call__), batch)\n",
        "    self.model.summary()\n",
        "\n",
        "  def distribute_dataset(self, dataset):\n",
        "    \"\"\"Create a distributed dataset.\"\"\"\n",
        "    if isinstance(dataset, tf.data.Dataset):\n",
        "      return self.strategy.experimental_distribute_dataset(dataset)\n",
        "    else:\n",
        "      return dataset\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    \"\"\"Distributed training step. Cust\"\"\"\n",
        "    # Wrap iterator in tf.function, slight speedup passing in iter vs batch.\n",
        "    batch = next(inputs) if hasattr(inputs, '__next__') else inputs\n",
        "    batch = rename_features(batch)\n",
        "    losses = self.run(self.step_fn, batch)\n",
        "    # Add up the scalar losses across replicas.\n",
        "    n_replicas = self.strategy.num_replicas_in_sync\n",
        "    return {k: self.psum(v, axis=None) / n_replicas for k, v in losses.items()}\n",
        "\n",
        "  @tf.function\n",
        "  def step_fn(self, batch):\n",
        "    #batch = rename_features(batch)\n",
        "    #print(batch)\n",
        "    \"\"\"Per-Replica training step.\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      _, losses = self.model(batch, return_losses=True, training=True)\n",
        "    # Clip and apply gradients.\n",
        "    grads = tape.gradient(losses['total_loss'], self.model.trainable_variables)\n",
        "    grads, _ = tf.clip_by_global_norm(grads, self.grad_clip_norm)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "    return losses\n",
        "\n",
        "\n",
        "@gin.configurable\n",
        "def get_trainer_class(trainer_class=Trainer2):\n",
        "  \"\"\"Gin configurable function get a 'global' trainer for use in ddsp_run.py.\n",
        "\n",
        "  Args:\n",
        "    trainer_class: A trainer class such as `Trainer`.\n",
        "\n",
        "  Returns:\n",
        "    The 'global' trainer class specifieed in the gin config.\n",
        "  \"\"\"\n",
        "  return trainer_class\n"
      ],
      "metadata": {
        "id": "PT0UJe2eWbAf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VUlAeW40Wsvr"
      },
      "outputs": [],
      "source": [
        "strategy = train_util.get_strategy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch[\"f0/confidence\"])\n",
        "batch[\"f0/confidence\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nijZir9eO8RY",
        "outputId": "c81d3132-2d5e-4ba9-b940-751f57894a99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.93773353 0.9452007  0.9449954  0.94677985 0.9500225  0.9442419\n",
            "  0.9516877  0.9541291  0.95147645 0.9489774  0.9571699  0.9511798\n",
            "  0.9456401  0.95614195 0.95160943 0.9398309  0.94929576 0.9497913\n",
            "  0.9439302  0.9446571  0.9476501  0.9394771  0.9335408  0.9433749\n",
            "  0.9443735  0.9304441  0.9416572  0.93890077 0.93091744 0.94296217\n",
            "  0.94381714 0.93011    0.9392348  0.93392503 0.929463   0.92636013\n",
            "  0.9317428  0.93493485 0.9192259  0.937116   0.9326004  0.9166105\n",
            "  0.9338255  0.9342736  0.923508   0.9348152  0.9357728  0.9272884\n",
            "  0.92266345 0.9256804  0.9312862  0.92052066 0.9327774  0.93385607\n",
            "  0.9126848  0.9234666  0.9220051  0.9135505  0.93121195 0.93198216\n",
            "  0.92891073 0.9284665  0.93140155 0.9248129  0.9141939  0.9240655\n",
            "  0.92860323 0.919415   0.93237054 0.9278046  0.9117222  0.92837995\n",
            "  0.9234501  0.9193841  0.93269217 0.9325123  0.9263015  0.92211556\n",
            "  0.9274379  0.92752564 0.91878635 0.92827904 0.93128616 0.9154526\n",
            "  0.92520875 0.920659   0.9121195  0.93025506 0.9314456  0.9262608\n",
            "  0.9342948  0.9347687  0.9231267  0.91982055 0.92678547 0.92871225\n",
            "  0.9214432  0.93279225 0.9327966  0.9140681  0.9251406  0.9192195\n",
            "  0.91225106 0.9326019  0.93386936 0.9299915  0.929348   0.9340885\n",
            "  0.9255171  0.9161792  0.92603266 0.930249   0.92202187 0.93294406\n",
            "  0.92803705 0.9129567  0.9303066  0.9238764  0.9192674  0.9337045\n",
            "  0.93302816 0.9264785  0.9233231  0.9285641  0.9277729  0.92041385\n",
            "  0.9295358  0.93209934 0.91663116 0.926148   0.9214833  0.9129503\n",
            "  0.9309742  0.931762   0.9267258  0.93470526 0.9352237  0.923279\n",
            "  0.9203773  0.9275124  0.92891526 0.9218313  0.93300045 0.9329847\n",
            "  0.91449034 0.9253273  0.9192239  0.91238844 0.9327942  0.9341022\n",
            "  0.9300804  0.9297091  0.9344728  0.9255941  0.91649467 0.92636824\n",
            "  0.9303924  0.9222437  0.9332031  0.9283099  0.9130621  0.9302629\n",
            "  0.9236506  0.91893613 0.9337704  0.9330503  0.9266664  0.92344236\n",
            "  0.9287125  0.92761946 0.9201497  0.9294683  0.9321307  0.9168114\n",
            "  0.92623234 0.9216992  0.91291875 0.93108296 0.9316799  0.9265977\n",
            "  0.9347602  0.9350943  0.9232613  0.9204341  0.9275464  0.92893493\n",
            "  0.92183566 0.9328729  0.9329854  0.9146617  0.9252559  0.9191187\n",
            "  0.9123019  0.93273187 0.93412507 0.93000364 0.92991817 0.9345952\n",
            "  0.9254787  0.91668355 0.9265559  0.93037647 0.9223608  0.93339837\n",
            "  0.9285331  0.9131454  0.930105   0.92349756 0.918748   0.9337698\n",
            "  0.9331799  0.926842   0.92363715 0.9288883  0.9275289  0.91990554\n",
            "  0.9293852  0.9321228  0.91699916 0.92629796 0.92190653 0.9128828\n",
            "  0.93121237 0.9315663  0.9264124  0.9348141  0.9349334  0.9231324\n",
            "  0.92049456 0.92758    0.928997   0.9219078  0.9327655  0.9330131\n",
            "  0.91481125 0.92519176 0.91904163 0.9122877  0.93267596 0.93418586\n",
            "  0.9299668  0.9301553  0.9347427  0.9253626  0.9167501  0.9266728\n",
            "  0.9301466  0.92236674 0.9334655  0.928777   0.91325045 0.9299594\n",
            "  0.9231672  0.91839445 0.93372065 0.93314    0.92689764 0.92367345\n",
            "  0.9290478  0.9273581  0.91972214 0.9292908  0.93203354 0.91713804\n",
            "  0.9263096  0.92210466 0.91288173 0.93134856 0.9314323  0.92621875\n",
            "  0.93489015 0.9347755  0.92307794 0.92061067 0.9275931  0.9290155\n",
            "  0.9219292  0.9326699  0.9331525  0.91480964 0.92509604 0.91882145\n",
            "  0.91202426 0.93261    0.93417007 0.92990726 0.93042344 0.93489397\n",
            "  0.92532945 0.91696763 0.92688155 0.93004453 0.92255116 0.93373007\n",
            "  0.92889273 0.91310537 0.9297572  0.92299366 0.9181733  0.9336628\n",
            "  0.93338513 0.9270497  0.9240865  0.92921925 0.9271548  0.9193731\n",
            "  0.92898834 0.932011   0.91762185 0.92660207 0.9223675  0.9128634\n",
            "  0.9314598  0.9311309  0.9259859  0.9349642  0.9347679  0.92328036\n",
            "  0.92080766 0.9278159  0.9289173  0.92196083 0.9326197  0.93316066\n",
            "  0.9148836  0.9249772  0.9187379  0.9120105  0.9324814  0.9340824\n",
            "  0.92974794 0.9306034  0.93497884 0.92507315 0.9169049  0.9269006\n",
            "  0.9296993  0.9224839  0.93358433 0.9291668  0.9132321  0.92962575\n",
            "  0.9222389  0.91728127 0.9335824  0.93309534 0.9270439  0.92402005\n",
            "  0.92964685 0.92740047 0.91975105 0.9295472  0.9323696  0.91822994\n",
            "  0.92687166 0.9230193  0.91363406 0.9318116  0.9309077  0.92552507\n",
            "  0.9346454  0.9341964  0.9229512  0.9202766  0.92705536 0.9285017\n",
            "  0.92182684 0.93243456 0.9331747  0.91480505 0.9247445  0.91861594\n",
            "  0.9121014  0.9326652  0.93411434 0.92990166 0.9308436  0.93490696\n",
            "  0.92564434 0.91687477 0.927225   0.92975557 0.9229412  0.93412256\n",
            "  0.9297155  0.91373456 0.9293864  0.9227357  0.9181737  0.9333879\n",
            "  0.9331335  0.9264141  0.9241872  0.92978513 0.92720044 0.9194577\n",
            "  0.92895204 0.93168455 0.9175433  0.9264988  0.92242926 0.91226214\n",
            "  0.93081766 0.93059623 0.9248363  0.93453074 0.9344065  0.92350173\n",
            "  0.9210588  0.9281392  0.9284003  0.92209965 0.932684   0.9328607\n",
            "  0.91475797 0.9254516  0.91885436 0.91305363 0.9328718  0.93425107\n",
            "  0.9298152  0.9317144  0.9352921  0.92344695 0.91577685 0.9244515\n",
            "  0.92749083 0.9208056  0.9317075  0.9295503  0.9136586  0.930048\n",
            "  0.9221504  0.91718864 0.93174213 0.9313928  0.9226804  0.9208809\n",
            "  0.92780834 0.9250606  0.9175215  0.9272733  0.93045235 0.91527975\n",
            "  0.9262997  0.91945314 0.90922886 0.9275629  0.9274858  0.92497456\n",
            "  0.9329277  0.93015325 0.9220824  0.911075   0.92631435 0.9250767\n",
            "  0.91785884 0.9288945  0.9258328  0.9056406  0.91962516 0.90563285\n",
            "  0.901862   0.9206914  0.9268472  0.92214215 0.9247588  0.9316753\n",
            "  0.91892064 0.90594447 0.9201542  0.9153938  0.9030229  0.91982615\n",
            "  0.9154455  0.9023643  0.9191436  0.9099176  0.8999895  0.9266621\n",
            "  0.9155308  0.9149483  0.90473497 0.91324115 0.90364546 0.8957199\n",
            "  0.908793   0.91163456 0.90984786 0.92005146 0.91407424 0.90060794\n",
            "  0.9182481  0.90910053 0.90237826 0.90289557 0.89426386 0.8796041\n",
            "  0.8808498  0.88192034 0.8480327  0.74557006 0.60252416 0.48249564\n",
            "  0.40420708 0.37740833 0.15413195 0.16021329 0.13071379 0.1319432\n",
            "  0.10673741 0.04911304 0.0813472  0.08298764 0.15149334 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]], shape=(1, 1000), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1000), dtype=float32, numpy=\n",
              "array([[0.93773353, 0.9452007 , 0.9449954 , 0.94677985, 0.9500225 ,\n",
              "        0.9442419 , 0.9516877 , 0.9541291 , 0.95147645, 0.9489774 ,\n",
              "        0.9571699 , 0.9511798 , 0.9456401 , 0.95614195, 0.95160943,\n",
              "        0.9398309 , 0.94929576, 0.9497913 , 0.9439302 , 0.9446571 ,\n",
              "        0.9476501 , 0.9394771 , 0.9335408 , 0.9433749 , 0.9443735 ,\n",
              "        0.9304441 , 0.9416572 , 0.93890077, 0.93091744, 0.94296217,\n",
              "        0.94381714, 0.93011   , 0.9392348 , 0.93392503, 0.929463  ,\n",
              "        0.92636013, 0.9317428 , 0.93493485, 0.9192259 , 0.937116  ,\n",
              "        0.9326004 , 0.9166105 , 0.9338255 , 0.9342736 , 0.923508  ,\n",
              "        0.9348152 , 0.9357728 , 0.9272884 , 0.92266345, 0.9256804 ,\n",
              "        0.9312862 , 0.92052066, 0.9327774 , 0.93385607, 0.9126848 ,\n",
              "        0.9234666 , 0.9220051 , 0.9135505 , 0.93121195, 0.93198216,\n",
              "        0.92891073, 0.9284665 , 0.93140155, 0.9248129 , 0.9141939 ,\n",
              "        0.9240655 , 0.92860323, 0.919415  , 0.93237054, 0.9278046 ,\n",
              "        0.9117222 , 0.92837995, 0.9234501 , 0.9193841 , 0.93269217,\n",
              "        0.9325123 , 0.9263015 , 0.92211556, 0.9274379 , 0.92752564,\n",
              "        0.91878635, 0.92827904, 0.93128616, 0.9154526 , 0.92520875,\n",
              "        0.920659  , 0.9121195 , 0.93025506, 0.9314456 , 0.9262608 ,\n",
              "        0.9342948 , 0.9347687 , 0.9231267 , 0.91982055, 0.92678547,\n",
              "        0.92871225, 0.9214432 , 0.93279225, 0.9327966 , 0.9140681 ,\n",
              "        0.9251406 , 0.9192195 , 0.91225106, 0.9326019 , 0.93386936,\n",
              "        0.9299915 , 0.929348  , 0.9340885 , 0.9255171 , 0.9161792 ,\n",
              "        0.92603266, 0.930249  , 0.92202187, 0.93294406, 0.92803705,\n",
              "        0.9129567 , 0.9303066 , 0.9238764 , 0.9192674 , 0.9337045 ,\n",
              "        0.93302816, 0.9264785 , 0.9233231 , 0.9285641 , 0.9277729 ,\n",
              "        0.92041385, 0.9295358 , 0.93209934, 0.91663116, 0.926148  ,\n",
              "        0.9214833 , 0.9129503 , 0.9309742 , 0.931762  , 0.9267258 ,\n",
              "        0.93470526, 0.9352237 , 0.923279  , 0.9203773 , 0.9275124 ,\n",
              "        0.92891526, 0.9218313 , 0.93300045, 0.9329847 , 0.91449034,\n",
              "        0.9253273 , 0.9192239 , 0.91238844, 0.9327942 , 0.9341022 ,\n",
              "        0.9300804 , 0.9297091 , 0.9344728 , 0.9255941 , 0.91649467,\n",
              "        0.92636824, 0.9303924 , 0.9222437 , 0.9332031 , 0.9283099 ,\n",
              "        0.9130621 , 0.9302629 , 0.9236506 , 0.91893613, 0.9337704 ,\n",
              "        0.9330503 , 0.9266664 , 0.92344236, 0.9287125 , 0.92761946,\n",
              "        0.9201497 , 0.9294683 , 0.9321307 , 0.9168114 , 0.92623234,\n",
              "        0.9216992 , 0.91291875, 0.93108296, 0.9316799 , 0.9265977 ,\n",
              "        0.9347602 , 0.9350943 , 0.9232613 , 0.9204341 , 0.9275464 ,\n",
              "        0.92893493, 0.92183566, 0.9328729 , 0.9329854 , 0.9146617 ,\n",
              "        0.9252559 , 0.9191187 , 0.9123019 , 0.93273187, 0.93412507,\n",
              "        0.93000364, 0.92991817, 0.9345952 , 0.9254787 , 0.91668355,\n",
              "        0.9265559 , 0.93037647, 0.9223608 , 0.93339837, 0.9285331 ,\n",
              "        0.9131454 , 0.930105  , 0.92349756, 0.918748  , 0.9337698 ,\n",
              "        0.9331799 , 0.926842  , 0.92363715, 0.9288883 , 0.9275289 ,\n",
              "        0.91990554, 0.9293852 , 0.9321228 , 0.91699916, 0.92629796,\n",
              "        0.92190653, 0.9128828 , 0.93121237, 0.9315663 , 0.9264124 ,\n",
              "        0.9348141 , 0.9349334 , 0.9231324 , 0.92049456, 0.92758   ,\n",
              "        0.928997  , 0.9219078 , 0.9327655 , 0.9330131 , 0.91481125,\n",
              "        0.92519176, 0.91904163, 0.9122877 , 0.93267596, 0.93418586,\n",
              "        0.9299668 , 0.9301553 , 0.9347427 , 0.9253626 , 0.9167501 ,\n",
              "        0.9266728 , 0.9301466 , 0.92236674, 0.9334655 , 0.928777  ,\n",
              "        0.91325045, 0.9299594 , 0.9231672 , 0.91839445, 0.93372065,\n",
              "        0.93314   , 0.92689764, 0.92367345, 0.9290478 , 0.9273581 ,\n",
              "        0.91972214, 0.9292908 , 0.93203354, 0.91713804, 0.9263096 ,\n",
              "        0.92210466, 0.91288173, 0.93134856, 0.9314323 , 0.92621875,\n",
              "        0.93489015, 0.9347755 , 0.92307794, 0.92061067, 0.9275931 ,\n",
              "        0.9290155 , 0.9219292 , 0.9326699 , 0.9331525 , 0.91480964,\n",
              "        0.92509604, 0.91882145, 0.91202426, 0.93261   , 0.93417007,\n",
              "        0.92990726, 0.93042344, 0.93489397, 0.92532945, 0.91696763,\n",
              "        0.92688155, 0.93004453, 0.92255116, 0.93373007, 0.92889273,\n",
              "        0.91310537, 0.9297572 , 0.92299366, 0.9181733 , 0.9336628 ,\n",
              "        0.93338513, 0.9270497 , 0.9240865 , 0.92921925, 0.9271548 ,\n",
              "        0.9193731 , 0.92898834, 0.932011  , 0.91762185, 0.92660207,\n",
              "        0.9223675 , 0.9128634 , 0.9314598 , 0.9311309 , 0.9259859 ,\n",
              "        0.9349642 , 0.9347679 , 0.92328036, 0.92080766, 0.9278159 ,\n",
              "        0.9289173 , 0.92196083, 0.9326197 , 0.93316066, 0.9148836 ,\n",
              "        0.9249772 , 0.9187379 , 0.9120105 , 0.9324814 , 0.9340824 ,\n",
              "        0.92974794, 0.9306034 , 0.93497884, 0.92507315, 0.9169049 ,\n",
              "        0.9269006 , 0.9296993 , 0.9224839 , 0.93358433, 0.9291668 ,\n",
              "        0.9132321 , 0.92962575, 0.9222389 , 0.91728127, 0.9335824 ,\n",
              "        0.93309534, 0.9270439 , 0.92402005, 0.92964685, 0.92740047,\n",
              "        0.91975105, 0.9295472 , 0.9323696 , 0.91822994, 0.92687166,\n",
              "        0.9230193 , 0.91363406, 0.9318116 , 0.9309077 , 0.92552507,\n",
              "        0.9346454 , 0.9341964 , 0.9229512 , 0.9202766 , 0.92705536,\n",
              "        0.9285017 , 0.92182684, 0.93243456, 0.9331747 , 0.91480505,\n",
              "        0.9247445 , 0.91861594, 0.9121014 , 0.9326652 , 0.93411434,\n",
              "        0.92990166, 0.9308436 , 0.93490696, 0.92564434, 0.91687477,\n",
              "        0.927225  , 0.92975557, 0.9229412 , 0.93412256, 0.9297155 ,\n",
              "        0.91373456, 0.9293864 , 0.9227357 , 0.9181737 , 0.9333879 ,\n",
              "        0.9331335 , 0.9264141 , 0.9241872 , 0.92978513, 0.92720044,\n",
              "        0.9194577 , 0.92895204, 0.93168455, 0.9175433 , 0.9264988 ,\n",
              "        0.92242926, 0.91226214, 0.93081766, 0.93059623, 0.9248363 ,\n",
              "        0.93453074, 0.9344065 , 0.92350173, 0.9210588 , 0.9281392 ,\n",
              "        0.9284003 , 0.92209965, 0.932684  , 0.9328607 , 0.91475797,\n",
              "        0.9254516 , 0.91885436, 0.91305363, 0.9328718 , 0.93425107,\n",
              "        0.9298152 , 0.9317144 , 0.9352921 , 0.92344695, 0.91577685,\n",
              "        0.9244515 , 0.92749083, 0.9208056 , 0.9317075 , 0.9295503 ,\n",
              "        0.9136586 , 0.930048  , 0.9221504 , 0.91718864, 0.93174213,\n",
              "        0.9313928 , 0.9226804 , 0.9208809 , 0.92780834, 0.9250606 ,\n",
              "        0.9175215 , 0.9272733 , 0.93045235, 0.91527975, 0.9262997 ,\n",
              "        0.91945314, 0.90922886, 0.9275629 , 0.9274858 , 0.92497456,\n",
              "        0.9329277 , 0.93015325, 0.9220824 , 0.911075  , 0.92631435,\n",
              "        0.9250767 , 0.91785884, 0.9288945 , 0.9258328 , 0.9056406 ,\n",
              "        0.91962516, 0.90563285, 0.901862  , 0.9206914 , 0.9268472 ,\n",
              "        0.92214215, 0.9247588 , 0.9316753 , 0.91892064, 0.90594447,\n",
              "        0.9201542 , 0.9153938 , 0.9030229 , 0.91982615, 0.9154455 ,\n",
              "        0.9023643 , 0.9191436 , 0.9099176 , 0.8999895 , 0.9266621 ,\n",
              "        0.9155308 , 0.9149483 , 0.90473497, 0.91324115, 0.90364546,\n",
              "        0.8957199 , 0.908793  , 0.91163456, 0.90984786, 0.92005146,\n",
              "        0.91407424, 0.90060794, 0.9182481 , 0.90910053, 0.90237826,\n",
              "        0.90289557, 0.89426386, 0.8796041 , 0.8808498 , 0.88192034,\n",
              "        0.8480327 , 0.74557006, 0.60252416, 0.48249564, 0.40420708,\n",
              "        0.37740833, 0.15413195, 0.16021329, 0.13071379, 0.1319432 ,\n",
              "        0.10673741, 0.04911304, 0.0813472 , 0.08298764, 0.15149334,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtPjCQxvQNqA",
        "outputId": "b5776f28-b2bd-4007-b190-baff9eb80d55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['audio', 'f0/confidence', 'f0/hz', 'loudness/db'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#batch[new_key] = batch.pop(old_key)\n",
        "\n",
        "def rename_features(batch):\n",
        "  batch['f0_confidence'] = batch.pop('f0/confidence')\n",
        "\n",
        "  batch['f0_hz'] = batch.pop('f0/hz')\n",
        "\n",
        "  batch['loudness_db'] = batch.pop('loudness/db')\n",
        "\n",
        "  return batch"
      ],
      "metadata": {
        "id": "waFrG5GZSghE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch.keys())"
      ],
      "metadata": {
        "id": "hKNWnccLTHy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8b5eeb-1cfb-4eca-a227-a8b95c32959b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['audio', 'f0/confidence', 'f0/hz', 'loudness/db'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_keys = batch.keys()\n",
        "new_keys = ['audio', 'f0_confidence', 'f0_hz', 'loudness_db']\n",
        "print(zip(batch_keys,new_keys))\n",
        "for key, key2 in zip(batch_keys,new_keys):\n",
        "  print(key, key2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqeuIt8pP2P-",
        "outputId": "60782de4-bbfc-4f8c-8748-6a34772f417e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<zip object at 0x7efe50262cc0>\n",
            "audio audio\n",
            "f0/confidence f0_confidence\n",
            "f0/hz f0_hz\n",
            "loudness/db loudness_db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0oFE75-A-Fk",
        "outputId": "daabb9a6-9db2-418e-8a9f-60694f3d3296"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00445393 0.10546707 0.2777211  ... 0.         0.         0.        ]], shape=(1, 64000), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op0V8onI0VUK"
      },
      "source": [
        "# Get model and trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWZQXFLehCU0"
      },
      "source": [
        "## python "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HCqXRY1KeX8S"
      },
      "outputs": [],
      "source": [
        "TIME_STEPS = 1000\n",
        "\n",
        "# Create Neural Networks.\n",
        "preprocessor = preprocessing.F0LoudnessPreprocessor(time_steps=TIME_STEPS)\n",
        "\n",
        "decoder = decoders.RnnFcDecoder(rnn_channels = 256,\n",
        "                                rnn_type = 'gru',\n",
        "                                ch = 256,\n",
        "                                layers_per_stack = 1,\n",
        "                                input_keys = ('ld_scaled', 'f0_scaled'),\n",
        "                                output_splits = (('amps', 1),\n",
        "                                                 ('harmonic_distribution', 45),\n",
        "                                                 ('noise_magnitudes', 45)))\n",
        "\n",
        "# Create Processors.\n",
        "harmonic = ddsp.synths.Harmonic(n_samples=n_samples, \n",
        "                                sample_rate=sample_rate,\n",
        "                                name='harmonic')\n",
        "\n",
        "noise = ddsp.synths.FilteredNoise(window_size=0,\n",
        "                                  initial_bias=-10.0,\n",
        "                                  name='noise')\n",
        "add = ddsp.processors.Add(name='add')\n",
        "\n",
        "# Create ProcessorGroup.\n",
        "dag = [(harmonic, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
        "       (noise, ['noise_magnitudes']),\n",
        "       (add, ['noise/signal', 'harmonic/signal'])]\n",
        "\n",
        "processor_group = ddsp.processors.ProcessorGroup(dag=dag,\n",
        "                                                 name='processor_group')\n",
        "\n",
        "\n",
        "# Loss_functions\n",
        "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
        "                                         mag_weight=1.0,\n",
        "                                         logmag_weight=1.0)\n",
        "\n",
        "with strategy.scope():\n",
        "  # Put it together in a model.\n",
        "  model = models.Autoencoder(preprocessor=preprocessor,\n",
        "                             encoder=None,\n",
        "                             decoder=decoder,\n",
        "                             processor_group=processor_group,\n",
        "                             losses=[spectral_loss])\n",
        "  trainer2 = Trainer2(model, strategy, learning_rate=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAZgDMV9hGyp"
      },
      "source": [
        "## or [`gin`](https://github.com/google/gin-config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1JPmTwQshVya"
      },
      "outputs": [],
      "source": [
        "gin_string = \"\"\"\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "\n",
        "# Preprocessor\n",
        "models.Autoencoder.preprocessor = @preprocessing.F0LoudnessPreprocessor()\n",
        "preprocessing.F0LoudnessPreprocessor.time_steps = 1000\n",
        "\n",
        "\n",
        "# Encoder\n",
        "models.Autoencoder.encoder = None\n",
        "\n",
        "# Decoder\n",
        "models.Autoencoder.decoder = @decoders.RnnFcDecoder()\n",
        "decoders.RnnFcDecoder.rnn_channels = 256\n",
        "decoders.RnnFcDecoder.rnn_type = 'gru'\n",
        "decoders.RnnFcDecoder.ch = 256\n",
        "decoders.RnnFcDecoder.layers_per_stack = 1\n",
        "decoders.RnnFcDecoder.input_keys = ('ld_scaled', 'f0_scaled')\n",
        "decoders.RnnFcDecoder.output_splits = (('amps', 1),\n",
        "                                       ('harmonic_distribution', 20),\n",
        "                                       ('noise_magnitudes', 20))\n",
        "\n",
        "# ProcessorGroup\n",
        "models.Autoencoder.processor_group = @processors.ProcessorGroup()\n",
        "\n",
        "processors.ProcessorGroup.dag = [\n",
        "  (@harmonic/synths.Harmonic(),\n",
        "    ['amps', 'harmonic_distribution', 'f0_hz']),\n",
        "  (@noise/synths.FilteredNoise(),\n",
        "    ['noise_magnitudes']),\n",
        "  (@add/processors.Add(),\n",
        "    ['noise/signal', 'harmonic/signal']),\n",
        "]\n",
        "\n",
        "# Harmonic Synthesizer\n",
        "harmonic/synths.Harmonic.name = 'harmonic'\n",
        "harmonic/synths.Harmonic.n_samples = 64000\n",
        "harmonic/synths.Harmonic.scale_fn = @core.exp_sigmoid\n",
        "\n",
        "# Filtered Noise Synthesizer\n",
        "noise/synths.FilteredNoise.name = 'noise'\n",
        "noise/synths.FilteredNoise.n_samples = 64000\n",
        "noise/synths.FilteredNoise.window_size = 0\n",
        "noise/synths.FilteredNoise.scale_fn = @core.exp_sigmoid\n",
        "noise/synths.FilteredNoise.initial_bias = -10.0\n",
        "\n",
        "# Add\n",
        "add/processors.Add.name = 'add'\n",
        "\n",
        "models.Autoencoder.losses = [\n",
        "    @losses.SpectralLoss(),\n",
        "]\n",
        "losses.SpectralLoss.loss_type = 'L1'\n",
        "losses.SpectralLoss.mag_weight = 1.0\n",
        "losses.SpectralLoss.logmag_weight = 1.0\n",
        "\"\"\"\n",
        "\n",
        "with gin.unlock_config():\n",
        "  gin.parse_config(gin_string)\n",
        "\n",
        "with strategy.scope():\n",
        "  # Autoencoder arguments are filled by gin.\n",
        "  model = ddsp.training.models.Autoencoder()\n",
        "  trainer = trainers.Trainer(model, strategy, learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnnxpYbRrPrp"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGvCE5BbrWTU"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1huyUYS5-P3",
        "outputId": "926e6e01-de37-4006-d5bd-255f0cc698e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RepeatDataset element_spec={'audio': TensorSpec(shape=(1, 64000), dtype=tf.float32, name=None), 'f0/confidence': TensorSpec(shape=(1, 1000), dtype=tf.float32, name=None), 'f0/hz': TensorSpec(shape=(1, 1000), dtype=tf.float32, name=None), 'loudness/db': TensorSpec(shape=(1, 1000), dtype=tf.float32, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1lQW604_QWm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7398f1e8-b596-44ad-bae0-077d838be02b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " f0_loudness_preprocessor (F  multiple                 0         \n",
            " 0LoudnessPreprocessor)                                          \n",
            "                                                                 \n",
            " rnn_fc_decoder (RnnFcDecode  multiple                 814171    \n",
            " r)                                                              \n",
            "                                                                 \n",
            " processor_group (ProcessorG  multiple                 0         \n",
            " roup)                                                           \n",
            "                                                                 \n",
            " spectral_loss (SpectralLoss  multiple                 0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 814,171\n",
            "Trainable params: 814,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build model, easiest to just run forward pass.\n",
        "dataset = trainer2.distribute_dataset(dataset)\n",
        "trainer2.build(rename_features(batch))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hExXWvDg5REG",
        "outputId": "9be4e281-2c28-4c79-ab2e-55ae916bcc42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.distribute.input_lib.DistributedDataset at 0x7efdfa0a09a0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFEqt6e1DsqG"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LWdoRIONDxri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f589f758-d50e-4f78-e554-37d87115600f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.distribute.input_lib.DistributedIterator object at 0x7efddcf4b490>\n",
            "step: 0\tspectral_loss: 18.31\ttotal_loss: 18.31\t\n",
            "step: 1\tspectral_loss: 19.08\ttotal_loss: 19.08\t\n",
            "step: 2\tspectral_loss: 25.06\ttotal_loss: 25.06\t\n",
            "step: 3\tspectral_loss: 17.25\ttotal_loss: 17.25\t\n",
            "step: 4\tspectral_loss: 17.25\ttotal_loss: 17.25\t\n",
            "step: 5\tspectral_loss: 16.06\ttotal_loss: 16.06\t\n",
            "step: 6\tspectral_loss: 17.15\ttotal_loss: 17.15\t\n",
            "step: 7\tspectral_loss: 15.93\ttotal_loss: 15.93\t\n",
            "step: 8\tspectral_loss: 14.99\ttotal_loss: 14.99\t\n",
            "step: 9\tspectral_loss: 14.76\ttotal_loss: 14.76\t\n",
            "step: 10\tspectral_loss: 14.29\ttotal_loss: 14.29\t\n",
            "step: 11\tspectral_loss: 14.34\ttotal_loss: 14.34\t\n",
            "step: 12\tspectral_loss: 14.24\ttotal_loss: 14.24\t\n",
            "step: 13\tspectral_loss: 14.13\ttotal_loss: 14.13\t\n",
            "step: 14\tspectral_loss: 13.97\ttotal_loss: 13.97\t\n",
            "step: 15\tspectral_loss: 14.16\ttotal_loss: 14.16\t\n",
            "step: 16\tspectral_loss: 14.08\ttotal_loss: 14.08\t\n",
            "step: 17\tspectral_loss: 13.88\ttotal_loss: 13.88\t\n",
            "step: 18\tspectral_loss: 13.79\ttotal_loss: 13.79\t\n",
            "step: 19\tspectral_loss: 13.80\ttotal_loss: 13.80\t\n",
            "step: 20\tspectral_loss: 13.57\ttotal_loss: 13.57\t\n",
            "step: 21\tspectral_loss: 13.46\ttotal_loss: 13.46\t\n",
            "step: 22\tspectral_loss: 13.40\ttotal_loss: 13.40\t\n",
            "step: 23\tspectral_loss: 13.25\ttotal_loss: 13.25\t\n",
            "step: 24\tspectral_loss: 13.19\ttotal_loss: 13.19\t\n",
            "step: 25\tspectral_loss: 13.32\ttotal_loss: 13.32\t\n",
            "step: 26\tspectral_loss: 13.33\ttotal_loss: 13.33\t\n",
            "step: 27\tspectral_loss: 13.18\ttotal_loss: 13.18\t\n",
            "step: 28\tspectral_loss: 13.04\ttotal_loss: 13.04\t\n",
            "step: 29\tspectral_loss: 13.09\ttotal_loss: 13.09\t\n",
            "step: 30\tspectral_loss: 12.95\ttotal_loss: 12.95\t\n",
            "step: 31\tspectral_loss: 12.92\ttotal_loss: 12.92\t\n",
            "step: 32\tspectral_loss: 12.91\ttotal_loss: 12.91\t\n",
            "step: 33\tspectral_loss: 12.79\ttotal_loss: 12.79\t\n",
            "step: 34\tspectral_loss: 12.74\ttotal_loss: 12.74\t\n",
            "step: 35\tspectral_loss: 12.83\ttotal_loss: 12.83\t\n",
            "step: 36\tspectral_loss: 12.75\ttotal_loss: 12.75\t\n",
            "step: 37\tspectral_loss: 12.71\ttotal_loss: 12.71\t\n",
            "step: 38\tspectral_loss: 12.71\ttotal_loss: 12.71\t\n",
            "step: 39\tspectral_loss: 12.61\ttotal_loss: 12.61\t\n",
            "step: 40\tspectral_loss: 12.49\ttotal_loss: 12.49\t\n",
            "step: 41\tspectral_loss: 12.49\ttotal_loss: 12.49\t\n",
            "step: 42\tspectral_loss: 12.35\ttotal_loss: 12.35\t\n",
            "step: 43\tspectral_loss: 11.98\ttotal_loss: 11.98\t\n",
            "step: 44\tspectral_loss: 12.11\ttotal_loss: 12.11\t\n",
            "step: 45\tspectral_loss: 12.20\ttotal_loss: 12.20\t\n",
            "step: 46\tspectral_loss: 12.04\ttotal_loss: 12.04\t\n",
            "step: 47\tspectral_loss: 11.81\ttotal_loss: 11.81\t\n",
            "step: 48\tspectral_loss: 11.65\ttotal_loss: 11.65\t\n",
            "step: 49\tspectral_loss: 11.65\ttotal_loss: 11.65\t\n",
            "step: 50\tspectral_loss: 11.62\ttotal_loss: 11.62\t\n",
            "step: 51\tspectral_loss: 11.53\ttotal_loss: 11.53\t\n",
            "step: 52\tspectral_loss: 11.48\ttotal_loss: 11.48\t\n",
            "step: 53\tspectral_loss: 11.51\ttotal_loss: 11.51\t\n",
            "step: 54\tspectral_loss: 11.44\ttotal_loss: 11.44\t\n",
            "step: 55\tspectral_loss: 11.69\ttotal_loss: 11.69\t\n",
            "step: 56\tspectral_loss: 11.71\ttotal_loss: 11.71\t\n",
            "step: 57\tspectral_loss: 11.51\ttotal_loss: 11.51\t\n",
            "step: 58\tspectral_loss: 11.47\ttotal_loss: 11.47\t\n",
            "step: 59\tspectral_loss: 11.28\ttotal_loss: 11.28\t\n",
            "step: 60\tspectral_loss: 11.05\ttotal_loss: 11.05\t\n",
            "step: 61\tspectral_loss: 10.92\ttotal_loss: 10.92\t\n",
            "step: 62\tspectral_loss: 11.06\ttotal_loss: 11.06\t\n",
            "step: 63\tspectral_loss: 11.07\ttotal_loss: 11.07\t\n",
            "step: 64\tspectral_loss: 11.03\ttotal_loss: 11.03\t\n",
            "step: 65\tspectral_loss: 10.91\ttotal_loss: 10.91\t\n",
            "step: 66\tspectral_loss: 10.89\ttotal_loss: 10.89\t\n",
            "step: 67\tspectral_loss: 10.84\ttotal_loss: 10.84\t\n",
            "step: 68\tspectral_loss: 10.67\ttotal_loss: 10.67\t\n",
            "step: 69\tspectral_loss: 10.51\ttotal_loss: 10.51\t\n",
            "step: 70\tspectral_loss: 10.32\ttotal_loss: 10.32\t\n",
            "step: 71\tspectral_loss: 10.24\ttotal_loss: 10.24\t\n",
            "step: 72\tspectral_loss: 10.40\ttotal_loss: 10.40\t\n",
            "step: 73\tspectral_loss: 10.37\ttotal_loss: 10.37\t\n",
            "step: 74\tspectral_loss: 10.25\ttotal_loss: 10.25\t\n",
            "step: 75\tspectral_loss: 10.16\ttotal_loss: 10.16\t\n",
            "step: 76\tspectral_loss: 10.16\ttotal_loss: 10.16\t\n",
            "step: 77\tspectral_loss: 10.11\ttotal_loss: 10.11\t\n",
            "step: 78\tspectral_loss: 10.03\ttotal_loss: 10.03\t\n",
            "step: 79\tspectral_loss: 9.96\ttotal_loss: 9.96\t\n",
            "step: 80\tspectral_loss: 9.84\ttotal_loss: 9.84\t\n",
            "step: 81\tspectral_loss: 9.68\ttotal_loss: 9.68\t\n",
            "step: 82\tspectral_loss: 9.44\ttotal_loss: 9.44\t\n",
            "step: 83\tspectral_loss: 9.31\ttotal_loss: 9.31\t\n",
            "step: 84\tspectral_loss: 9.28\ttotal_loss: 9.28\t\n",
            "step: 85\tspectral_loss: 9.26\ttotal_loss: 9.26\t\n",
            "step: 86\tspectral_loss: 9.20\ttotal_loss: 9.20\t\n",
            "step: 87\tspectral_loss: 9.15\ttotal_loss: 9.15\t\n",
            "step: 88\tspectral_loss: 9.05\ttotal_loss: 9.05\t\n",
            "step: 89\tspectral_loss: 8.96\ttotal_loss: 8.96\t\n",
            "step: 90\tspectral_loss: 8.92\ttotal_loss: 8.92\t\n",
            "step: 91\tspectral_loss: 8.99\ttotal_loss: 8.99\t\n",
            "step: 92\tspectral_loss: 9.04\ttotal_loss: 9.04\t\n",
            "step: 93\tspectral_loss: 8.92\ttotal_loss: 8.92\t\n",
            "step: 94\tspectral_loss: 9.11\ttotal_loss: 9.11\t\n",
            "step: 95\tspectral_loss: 9.06\ttotal_loss: 9.06\t\n",
            "step: 96\tspectral_loss: 8.80\ttotal_loss: 8.80\t\n",
            "step: 97\tspectral_loss: 8.72\ttotal_loss: 8.72\t\n",
            "step: 98\tspectral_loss: 8.83\ttotal_loss: 8.83\t\n",
            "step: 99\tspectral_loss: 8.74\ttotal_loss: 8.74\t\n",
            "step: 100\tspectral_loss: 8.82\ttotal_loss: 8.82\t\n",
            "step: 101\tspectral_loss: 8.89\ttotal_loss: 8.89\t\n",
            "step: 102\tspectral_loss: 8.70\ttotal_loss: 8.70\t\n",
            "step: 103\tspectral_loss: 9.01\ttotal_loss: 9.01\t\n",
            "step: 104\tspectral_loss: 9.18\ttotal_loss: 9.18\t\n",
            "step: 105\tspectral_loss: 8.86\ttotal_loss: 8.86\t\n",
            "step: 106\tspectral_loss: 8.84\ttotal_loss: 8.84\t\n",
            "step: 107\tspectral_loss: 8.96\ttotal_loss: 8.96\t\n",
            "step: 108\tspectral_loss: 8.77\ttotal_loss: 8.77\t\n",
            "step: 109\tspectral_loss: 8.70\ttotal_loss: 8.70\t\n",
            "step: 110\tspectral_loss: 8.73\ttotal_loss: 8.73\t\n",
            "step: 111\tspectral_loss: 8.59\ttotal_loss: 8.59\t\n",
            "step: 112\tspectral_loss: 8.72\ttotal_loss: 8.72\t\n",
            "step: 113\tspectral_loss: 8.86\ttotal_loss: 8.86\t\n",
            "step: 114\tspectral_loss: 8.66\ttotal_loss: 8.66\t\n",
            "step: 115\tspectral_loss: 8.63\ttotal_loss: 8.63\t\n",
            "step: 116\tspectral_loss: 8.69\ttotal_loss: 8.69\t\n",
            "step: 117\tspectral_loss: 8.53\ttotal_loss: 8.53\t\n",
            "step: 118\tspectral_loss: 8.60\ttotal_loss: 8.60\t\n",
            "step: 119\tspectral_loss: 8.73\ttotal_loss: 8.73\t\n",
            "step: 120\tspectral_loss: 8.56\ttotal_loss: 8.56\t\n",
            "step: 121\tspectral_loss: 8.54\ttotal_loss: 8.54\t\n",
            "step: 122\tspectral_loss: 8.60\ttotal_loss: 8.60\t\n",
            "step: 123\tspectral_loss: 8.46\ttotal_loss: 8.46\t\n",
            "step: 124\tspectral_loss: 8.61\ttotal_loss: 8.61\t\n",
            "step: 125\tspectral_loss: 8.73\ttotal_loss: 8.73\t\n",
            "step: 126\tspectral_loss: 8.54\ttotal_loss: 8.54\t\n",
            "step: 127\tspectral_loss: 8.45\ttotal_loss: 8.45\t\n",
            "step: 128\tspectral_loss: 8.41\ttotal_loss: 8.41\t\n",
            "step: 129\tspectral_loss: 8.24\ttotal_loss: 8.24\t\n",
            "step: 130\tspectral_loss: 8.07\ttotal_loss: 8.07\t\n",
            "step: 131\tspectral_loss: 7.99\ttotal_loss: 7.99\t\n",
            "step: 132\tspectral_loss: 8.06\ttotal_loss: 8.06\t\n",
            "step: 133\tspectral_loss: 8.03\ttotal_loss: 8.03\t\n",
            "step: 134\tspectral_loss: 7.95\ttotal_loss: 7.95\t\n",
            "step: 135\tspectral_loss: 7.89\ttotal_loss: 7.89\t\n",
            "step: 136\tspectral_loss: 7.98\ttotal_loss: 7.98\t\n",
            "step: 137\tspectral_loss: 8.02\ttotal_loss: 8.02\t\n",
            "step: 138\tspectral_loss: 8.10\ttotal_loss: 8.10\t\n",
            "step: 139\tspectral_loss: 8.03\ttotal_loss: 8.03\t\n",
            "step: 140\tspectral_loss: 7.92\ttotal_loss: 7.92\t\n",
            "step: 141\tspectral_loss: 7.89\ttotal_loss: 7.89\t\n",
            "step: 142\tspectral_loss: 7.88\ttotal_loss: 7.88\t\n",
            "step: 143\tspectral_loss: 7.89\ttotal_loss: 7.89\t\n",
            "step: 144\tspectral_loss: 7.96\ttotal_loss: 7.96\t\n",
            "step: 145\tspectral_loss: 7.92\ttotal_loss: 7.92\t\n",
            "step: 146\tspectral_loss: 7.89\ttotal_loss: 7.89\t\n",
            "step: 147\tspectral_loss: 7.88\ttotal_loss: 7.88\t\n",
            "step: 148\tspectral_loss: 7.85\ttotal_loss: 7.85\t\n",
            "step: 149\tspectral_loss: 7.82\ttotal_loss: 7.82\t\n",
            "step: 150\tspectral_loss: 7.86\ttotal_loss: 7.86\t\n",
            "step: 151\tspectral_loss: 7.86\ttotal_loss: 7.86\t\n",
            "step: 152\tspectral_loss: 7.80\ttotal_loss: 7.80\t\n",
            "step: 153\tspectral_loss: 7.78\ttotal_loss: 7.78\t\n",
            "step: 154\tspectral_loss: 7.86\ttotal_loss: 7.86\t\n",
            "step: 155\tspectral_loss: 7.86\ttotal_loss: 7.86\t\n",
            "step: 156\tspectral_loss: 7.79\ttotal_loss: 7.79\t\n",
            "step: 157\tspectral_loss: 7.76\ttotal_loss: 7.76\t\n",
            "step: 158\tspectral_loss: 7.84\ttotal_loss: 7.84\t\n",
            "step: 159\tspectral_loss: 7.80\ttotal_loss: 7.80\t\n",
            "step: 160\tspectral_loss: 7.79\ttotal_loss: 7.79\t\n",
            "step: 161\tspectral_loss: 7.76\ttotal_loss: 7.76\t\n",
            "step: 162\tspectral_loss: 7.78\ttotal_loss: 7.78\t\n",
            "step: 163\tspectral_loss: 7.79\ttotal_loss: 7.79\t\n",
            "step: 164\tspectral_loss: 7.76\ttotal_loss: 7.76\t\n",
            "step: 165\tspectral_loss: 7.86\ttotal_loss: 7.86\t\n",
            "step: 166\tspectral_loss: 7.76\ttotal_loss: 7.76\t\n",
            "step: 167\tspectral_loss: 7.84\ttotal_loss: 7.84\t\n",
            "step: 168\tspectral_loss: 7.93\ttotal_loss: 7.93\t\n",
            "step: 169\tspectral_loss: 7.75\ttotal_loss: 7.75\t\n",
            "step: 170\tspectral_loss: 7.74\ttotal_loss: 7.74\t\n",
            "step: 171\tspectral_loss: 7.73\ttotal_loss: 7.73\t\n",
            "step: 172\tspectral_loss: 7.55\ttotal_loss: 7.55\t\n",
            "step: 173\tspectral_loss: 7.46\ttotal_loss: 7.46\t\n",
            "step: 174\tspectral_loss: 7.39\ttotal_loss: 7.39\t\n",
            "step: 175\tspectral_loss: 7.23\ttotal_loss: 7.23\t\n",
            "step: 176\tspectral_loss: 7.25\ttotal_loss: 7.25\t\n",
            "step: 177\tspectral_loss: 7.23\ttotal_loss: 7.23\t\n",
            "step: 178\tspectral_loss: 7.09\ttotal_loss: 7.09\t\n",
            "step: 179\tspectral_loss: 6.97\ttotal_loss: 6.97\t\n",
            "step: 180\tspectral_loss: 6.85\ttotal_loss: 6.85\t\n",
            "step: 181\tspectral_loss: 6.47\ttotal_loss: 6.47\t\n",
            "step: 182\tspectral_loss: 6.56\ttotal_loss: 6.56\t\n",
            "step: 183\tspectral_loss: 6.85\ttotal_loss: 6.85\t\n",
            "step: 184\tspectral_loss: 6.83\ttotal_loss: 6.83\t\n",
            "step: 185\tspectral_loss: 6.82\ttotal_loss: 6.82\t\n",
            "step: 186\tspectral_loss: 6.84\ttotal_loss: 6.84\t\n",
            "step: 187\tspectral_loss: 6.71\ttotal_loss: 6.71\t\n",
            "step: 188\tspectral_loss: 6.60\ttotal_loss: 6.60\t\n",
            "step: 189\tspectral_loss: 6.47\ttotal_loss: 6.47\t\n",
            "step: 190\tspectral_loss: 6.29\ttotal_loss: 6.29\t\n",
            "step: 191\tspectral_loss: 6.32\ttotal_loss: 6.32\t\n",
            "step: 192\tspectral_loss: 6.43\ttotal_loss: 6.43\t\n",
            "step: 193\tspectral_loss: 6.42\ttotal_loss: 6.42\t\n",
            "step: 194\tspectral_loss: 6.43\ttotal_loss: 6.43\t\n",
            "step: 195\tspectral_loss: 6.41\ttotal_loss: 6.41\t\n",
            "step: 196\tspectral_loss: 6.30\ttotal_loss: 6.30\t\n",
            "step: 197\tspectral_loss: 6.32\ttotal_loss: 6.32\t\n",
            "step: 198\tspectral_loss: 6.37\ttotal_loss: 6.37\t\n",
            "step: 199\tspectral_loss: 6.31\ttotal_loss: 6.31\t\n",
            "step: 200\tspectral_loss: 6.52\ttotal_loss: 6.52\t\n",
            "step: 201\tspectral_loss: 6.51\ttotal_loss: 6.51\t\n",
            "step: 202\tspectral_loss: 6.24\ttotal_loss: 6.24\t\n",
            "step: 203\tspectral_loss: 6.27\ttotal_loss: 6.27\t\n",
            "step: 204\tspectral_loss: 6.37\ttotal_loss: 6.37\t\n",
            "step: 205\tspectral_loss: 6.19\ttotal_loss: 6.19\t\n",
            "step: 206\tspectral_loss: 6.02\ttotal_loss: 6.02\t\n",
            "step: 207\tspectral_loss: 6.09\ttotal_loss: 6.09\t\n",
            "step: 208\tspectral_loss: 6.10\ttotal_loss: 6.10\t\n",
            "step: 209\tspectral_loss: 6.11\ttotal_loss: 6.11\t\n",
            "step: 210\tspectral_loss: 6.13\ttotal_loss: 6.13\t\n",
            "step: 211\tspectral_loss: 6.03\ttotal_loss: 6.03\t\n",
            "step: 212\tspectral_loss: 6.07\ttotal_loss: 6.07\t\n",
            "step: 213\tspectral_loss: 6.15\ttotal_loss: 6.15\t\n",
            "step: 214\tspectral_loss: 6.04\ttotal_loss: 6.04\t\n",
            "step: 215\tspectral_loss: 5.97\ttotal_loss: 5.97\t\n",
            "step: 216\tspectral_loss: 6.02\ttotal_loss: 6.02\t\n",
            "step: 217\tspectral_loss: 5.95\ttotal_loss: 5.95\t\n",
            "step: 218\tspectral_loss: 6.01\ttotal_loss: 6.01\t\n",
            "step: 219\tspectral_loss: 6.06\ttotal_loss: 6.06\t\n",
            "step: 220\tspectral_loss: 5.98\ttotal_loss: 5.98\t\n",
            "step: 221\tspectral_loss: 6.01\ttotal_loss: 6.01\t\n",
            "step: 222\tspectral_loss: 6.08\ttotal_loss: 6.08\t\n",
            "step: 223\tspectral_loss: 5.96\ttotal_loss: 5.96\t\n",
            "step: 224\tspectral_loss: 5.99\ttotal_loss: 5.99\t\n",
            "step: 225\tspectral_loss: 6.02\ttotal_loss: 6.02\t\n",
            "step: 226\tspectral_loss: 5.92\ttotal_loss: 5.92\t\n",
            "step: 227\tspectral_loss: 5.99\ttotal_loss: 5.99\t\n",
            "step: 228\tspectral_loss: 6.06\ttotal_loss: 6.06\t\n",
            "step: 229\tspectral_loss: 5.95\ttotal_loss: 5.95\t\n",
            "step: 230\tspectral_loss: 5.93\ttotal_loss: 5.93\t\n",
            "step: 231\tspectral_loss: 6.00\ttotal_loss: 6.00\t\n",
            "step: 232\tspectral_loss: 5.91\ttotal_loss: 5.91\t\n",
            "step: 233\tspectral_loss: 5.94\ttotal_loss: 5.94\t\n",
            "step: 234\tspectral_loss: 6.01\ttotal_loss: 6.01\t\n",
            "step: 235\tspectral_loss: 5.89\ttotal_loss: 5.89\t\n",
            "step: 236\tspectral_loss: 5.95\ttotal_loss: 5.95\t\n",
            "step: 237\tspectral_loss: 6.02\ttotal_loss: 6.02\t\n",
            "step: 238\tspectral_loss: 5.90\ttotal_loss: 5.90\t\n",
            "step: 239\tspectral_loss: 5.87\ttotal_loss: 5.87\t\n",
            "step: 240\tspectral_loss: 5.90\ttotal_loss: 5.90\t\n",
            "step: 241\tspectral_loss: 5.83\ttotal_loss: 5.83\t\n",
            "step: 242\tspectral_loss: 5.91\ttotal_loss: 5.91\t\n",
            "step: 243\tspectral_loss: 5.98\ttotal_loss: 5.98\t\n",
            "step: 244\tspectral_loss: 5.87\ttotal_loss: 5.87\t\n",
            "step: 245\tspectral_loss: 5.86\ttotal_loss: 5.86\t\n",
            "step: 246\tspectral_loss: 5.94\ttotal_loss: 5.94\t\n",
            "step: 247\tspectral_loss: 5.85\ttotal_loss: 5.85\t\n",
            "step: 248\tspectral_loss: 5.85\ttotal_loss: 5.85\t\n",
            "step: 249\tspectral_loss: 5.89\ttotal_loss: 5.89\t\n",
            "step: 250\tspectral_loss: 5.81\ttotal_loss: 5.81\t\n",
            "step: 251\tspectral_loss: 5.92\ttotal_loss: 5.92\t\n",
            "step: 252\tspectral_loss: 5.98\ttotal_loss: 5.98\t\n",
            "step: 253\tspectral_loss: 5.87\ttotal_loss: 5.87\t\n",
            "step: 254\tspectral_loss: 5.83\ttotal_loss: 5.83\t\n",
            "step: 255\tspectral_loss: 5.83\ttotal_loss: 5.83\t\n",
            "step: 256\tspectral_loss: 5.79\ttotal_loss: 5.79\t\n",
            "step: 257\tspectral_loss: 5.91\ttotal_loss: 5.91\t\n",
            "step: 258\tspectral_loss: 6.04\ttotal_loss: 6.04\t\n",
            "step: 259\tspectral_loss: 5.92\ttotal_loss: 5.92\t\n",
            "step: 260\tspectral_loss: 5.82\ttotal_loss: 5.82\t\n",
            "step: 261\tspectral_loss: 5.85\ttotal_loss: 5.85\t\n",
            "step: 262\tspectral_loss: 5.83\ttotal_loss: 5.83\t\n",
            "step: 263\tspectral_loss: 5.84\ttotal_loss: 5.84\t\n",
            "step: 264\tspectral_loss: 5.84\ttotal_loss: 5.84\t\n",
            "step: 265\tspectral_loss: 5.77\ttotal_loss: 5.77\t\n",
            "step: 266\tspectral_loss: 5.78\ttotal_loss: 5.78\t\n",
            "step: 267\tspectral_loss: 5.86\ttotal_loss: 5.86\t\n",
            "step: 268\tspectral_loss: 5.80\ttotal_loss: 5.80\t\n",
            "step: 269\tspectral_loss: 5.82\ttotal_loss: 5.82\t\n",
            "step: 270\tspectral_loss: 5.86\ttotal_loss: 5.86\t\n",
            "step: 271\tspectral_loss: 5.77\ttotal_loss: 5.77\t\n",
            "step: 272\tspectral_loss: 5.73\ttotal_loss: 5.73\t\n",
            "step: 273\tspectral_loss: 5.77\ttotal_loss: 5.77\t\n",
            "step: 274\tspectral_loss: 5.74\ttotal_loss: 5.74\t\n",
            "step: 275\tspectral_loss: 5.78\ttotal_loss: 5.78\t\n",
            "step: 276\tspectral_loss: 5.84\ttotal_loss: 5.84\t\n",
            "step: 277\tspectral_loss: 5.74\ttotal_loss: 5.74\t\n",
            "step: 278\tspectral_loss: 5.72\ttotal_loss: 5.72\t\n",
            "step: 279\tspectral_loss: 5.75\ttotal_loss: 5.75\t\n",
            "step: 280\tspectral_loss: 5.78\ttotal_loss: 5.78\t\n",
            "step: 281\tspectral_loss: 5.75\ttotal_loss: 5.75\t\n",
            "step: 282\tspectral_loss: 5.77\ttotal_loss: 5.77\t\n",
            "step: 283\tspectral_loss: 5.85\ttotal_loss: 5.85\t\n",
            "step: 284\tspectral_loss: 5.78\ttotal_loss: 5.78\t\n",
            "step: 285\tspectral_loss: 5.79\ttotal_loss: 5.79\t\n",
            "step: 286\tspectral_loss: 5.87\ttotal_loss: 5.87\t\n",
            "step: 287\tspectral_loss: 5.80\ttotal_loss: 5.80\t\n",
            "step: 288\tspectral_loss: 5.77\ttotal_loss: 5.77\t\n",
            "step: 289\tspectral_loss: 5.80\ttotal_loss: 5.80\t\n",
            "step: 290\tspectral_loss: 5.73\ttotal_loss: 5.73\t\n",
            "step: 291\tspectral_loss: 5.77\ttotal_loss: 5.77\t\n",
            "step: 292\tspectral_loss: 5.82\ttotal_loss: 5.82\t\n",
            "step: 293\tspectral_loss: 5.74\ttotal_loss: 5.74\t\n",
            "step: 294\tspectral_loss: 5.72\ttotal_loss: 5.72\t\n",
            "step: 295\tspectral_loss: 5.74\ttotal_loss: 5.74\t\n",
            "step: 296\tspectral_loss: 5.66\ttotal_loss: 5.66\t\n",
            "step: 297\tspectral_loss: 5.73\ttotal_loss: 5.73\t\n",
            "step: 298\tspectral_loss: 5.80\ttotal_loss: 5.80\t\n",
            "step: 299\tspectral_loss: 5.70\ttotal_loss: 5.70\t\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset_iter = iter(dataset)\n",
        "print(dataset_iter)\n",
        "for i in range(300):\n",
        "  losses = trainer2.train_step(dataset_iter)\n",
        "  res_str = 'step: {}\\t'.format(i)\n",
        "  for k, v in losses.items():\n",
        "    res_str += '{}: {:.2f}\\t'.format(k, v)\n",
        "  print(res_str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_iter.element_spec)"
      ],
      "metadata": {
        "id": "a-RT6YS4zZe8",
        "outputId": "de032f2a-37de-4b6d-e01f-9ef678e13502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'audio': TensorSpec(shape=(1, 64000), dtype=tf.float32, name=None), 'f0/confidence': TensorSpec(shape=(1, 1000), dtype=tf.float32, name=None), 'f0/hz': TensorSpec(shape=(1, 1000), dtype=tf.float32, name=None), 'loudness/db': TensorSpec(shape=(1, 1000), dtype=tf.float32, name=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cj220vSF8_Y"
      },
      "source": [
        "# Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mDU_FysURm_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a4ffb3-e9e6-405d-cb47-151ef2c65b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction took 0.4 seconds\n"
          ]
        }
      ],
      "source": [
        "# Run a batch of predictions.\n",
        "start_time = time.time()\n",
        "controls =  model(rename_features(next(dataset_iter)))\n",
        "audio_gen = model.get_audio_from_outputs(controls)\n",
        "print('Prediction took %.1f seconds' % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AlE5kkroHiFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "902e77a9-11e8-4e87-9705-7c00b8cad325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Audio\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_2\"> </div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resynthesized Audio\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_3\"> </div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Noise Audio\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"id_4\"> </div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x442.347 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x442.347 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAF2CAYAAACoK+4UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5gkV3no/++p0LmnpyfPzszuanNQQBkEFkIgMMboApZlLLAxzjbcH8aRjOCCAwZHLhdsMMmARZAx2ICQQEIIhUV5tUmb0+TU3dPTqarO74/TPTOrDTMrZnZg6/08zz7b02+fqlPV/XadOnVOtdJaI4Q4/1nLXQEhxLkhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQIeEsxUKVUjIsT4hlorVWp3p+SZLdsJdu0UKI0/BPG5FmvBAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyC3HeUGeMSrILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChIQkuxAhIckuREhIsgsREpLsQpw3zpzOkuxChIQkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLkRISLILERKS7EKEhCS7EOcJJfegE0KAJLsQoSHJLkRISLILERKS7EKEhCS7ECEhyS5ESEiyC3G+UHKnGiEEkuxChIYkuxAhIckuREhIsgsREpLsQoSEJLsQISHJLsR5Q66zCyGQZBciNCTZhQgJSXYhQkKSXYiQkGQXIiQk2YU4TyiZ4iqEAEl2IUJDkl2IkJBkFyIkJNmFCAlJdiHOG9IbL4RAkl2I0FhQsiulLlrqigghltZCj+wfU0ptU0r9oVIqs6Q1EkIsiQUlu9b654DXAX3AI0qpLyqlbljSmgkhFpXSWi/8xUrZwKuAfwLygALeobW+/Rmv02AvZj2FEPOwrBRBkENrrU4ZX8hClFIXK6X+HtgFXA+8Umu9uf747xettkKIZ22+iTDOApfzz8AnMUfxUuNJrXW/Uupdz756QohzZUHNeKVUCihprf363xYQ01pPn+b10owX4hyz7SZ8f+Ina8YDdwHxOX8n6s8JIX5GLDTZY1rrqcYf9ceJpamSEGIpLDTZi0qpyxp/KKUuB0pneL0Q4qfMQjvo/gj4ilKqH3O5rQv4lSWrlRDirKl5jt0Lvs6ulHKBjfU/92ita2d4rXTQCXGOOXYznj922g66hR7ZAa4EVtfLXKaUQmv9uUWooxDiHFhQsiulPg+sBR4H/PrTGpBkF+JnxEKP7FcAW/TZjK0VQvxUWWhv/FOYTjkhxE+rRRou2wbsVEptAyqNJ7XWNz77mgkhzqWFJvutS1kJIcTSW1Cya61/oJRaBazXWt+llEog19aE+Jmy0CmuvwN8FfhE/ake4OtLVSkhxOJbaAfdm4DnY25YgdZ6L9CxVJUSQpy9+UbQLTTZK1rr6sxClXIw19mFED8jFprsP1BKvQOI1+899xXgm0tXLSHEYlvozSss4LeAl2ImwtwBfPJ0g2xkbLwQ557rtFHzhk47Nv6sbji5UJLsQpx78yX7QsfGH+QU5+ha6zU/Yf2EEOfI2YyNb4gBvwy0LH51hBDP1nx3l33WzXil1CNa68tPE5NmvBDnWMTtoFob+Imb8ZfN+dPCHOnPZi68EGKZLTRhPzLnsQccAm5e9NoIIZbMQsfGv2ipKyKEWFoLbcb/8ZniWuu/W5zqCCGerfmGy55Nb/yVwDfqf78S2AbsfdY1E0KcUwtN9l7gMq11AUApdSvwP1rr1y9VxYQQi2uhY+M7geqcv6v154QQPyMWemT/HLBNKfWf9b9fBXx2aaokhHg2Fm1QTf1a+8/V/7xXa/3YGV4rg2qEOMdikRWUq0d/4l9xBfNDjnmt9T8Cx5RSFyxKDYUQ58RCb0v1XuAvgLfXn3KBf1+qSgkhFt9Cj+yvBm4EigBa634gvVSVEkIsvoUme7V+owoNoJRKLl2VhBDPxnwddAtN9i8rpT4BNNfvNHsX8K8/Yd2EEOfQvJfelFIKuA3YhLm77EbgPVrrO5e4bkKIRTRvsmuttVLqW1rriwBJcCF+Ri20Gf+oUurKJa2JEGJJLXQE3dXA65VShzA98gpz0L94qSomhDg7ap6BbGdMdqXUSq31EeBli1kpIcS5N9+R/euY2W6HlVJf01r/0rmolBBi8c13zj53jK3cNlqIn2HzJbs+zWMhxE+Z+QbVzNeMv0Qplccc4eP1xzDbQdf0k1dRCHEunDHZtdYyT1WI88TZTHEVQvwMk2QX4jyxWBNhhBA/4yTZhQgJSXYhzhPSjBdCAJLsQoSGJLsQISHJLsR5Yr4fdpRkFyIkJNmFCAlJdiHOE3LpTQgBSLILERqS7EKEhCS7EOcJpc58+wlJdiFCQpJdiJCQZBfiPCEj6IQQgCS7EKEhyS7EeUJG0AkhAEl2IUJDkl2IkJBkF+I8YcmlNyEESLILcd6QsfFCCECSXYjQkGQXIiQk2YU4T8hEGCEEIMkuxHlDxsYLIQBJdiFCQ5JdiPOEQgbVCCGQZBciNCTZhThPWNIbL4QASXYhzhvSQSeEACTZhQgNSXYhzhMyEUYIAUiyCxEakuxCnCcs6Y0XQoAkuxDnDZnPLoQAJNmFOG/IpTchBCDJLsR5Q3rjhRCAJLsQ5w05ZxdCAJLsQpw35JxdCAFIsgtx3pBzdiEEIMkuxHnDkiO7EAIk2YU4b0hvvBACkGQX4rwhvfFCCECSXYjzhqXlyC6EQJJdiPOGXGcXQgCS7EKcN+RXXIUQgCS7EOcNOWcXIiQs1DxxIUQoSLIL8SwpFVvuKpxAyaAaIZaG1uXlrsIJ5JxdiCWysvmlMM958k8TSXYhnoXe5hezXl/Iluxrl7sqM+TILsQSuFRdAcBznDXLXJOFk2QX4ll4YVeEv7u8wpXtPz0pJJfehFgCndGAvu5Jmt1guasyQ25eIcQS6ImXSW1UdEZry12VGXJkF2IJuFaAchQt0cpyV2XBJNmFOEsKh6FylNGHLbLxn55r7XJkF2KRRdw2JmsOX969EscOSMXXLneVgPmT3TlH9RDivJGIdtAbr7ChdYJs2zRTpf3YdhO+n1+mGi1sYI8c2YU4S+3uBrZ0jLH6N9LE2jWWlVrGRIdYpBvQKGnGC7G4UroZrRW6XGNod4LW1GYsK7Fs9XHsOCDn7EIsunbdTDRWQ994PSt/t5Wfc15CW+qiZauPJLsQSyRi2bRcHKBTTejJIusyLim7Y1nrtJDptpLsQpwlWymcy/sAGPjaNN1xTVq3LFt9PL8EgFJyZBdiUY360+CYO7mu+NM1JGxNTVWXrT5aB6A9acYLsdi2e3dCrghBgH/N89jSVOSG9PplqYvCIepmUFZk3gtwkuxCnKVfbb4JXZ4dE9/XnKfk6WWpi+00kbI70NrDkma8EIvr1b1lVHcWNVUAIJmsUvKXZ/ZbNrGWlXoT5tYVkuxCLKqeVBHd1oJOJgGwoz7rm878ayxLJWo10aRiWFaEeQ7skuxCnK2VqyfQba3Yd/0ANTmBZcMlzcsz+62VXjpjEbQO5MguxGJzm+sP0glwXVIXR4hay9OMj+gYMUdhWZF5XyvJLsRZcjoj4LrU7tiF9fRerOdt4rbD0WWpS5wYSUdhKUea8UIsNhWxwHH4h6+tI+hZgc5m+IMNhWWpi4OFpcDzp6UZL8RiU64NQcCffVRh7d6Lbm4m6njLUhcXu57iAbYlyS7E4rIURKMwnmfiX/eB73GokFqWqjjKpHAq1jfvayXZhThbkfpltnSc7K+vBDfCL/7G2LJUJeO6JB0ItIct5+xCLLKoC74PLc2U7ziAGh9HtaeXpSpJ1yLpaJQy5+5nIskuxFlSXS3opgy1rz9G7IYLUHsOQrA8w2U744pViRpJt1PuVCPEoktEIQhw1mWg6kE2jc5NL0tV0i5kXI/B3H1yZF9si3f7oZ+dX/9cemfeF/PdmKEl/ZzFrMz8lIWqlFEXr4X2ZiY/sZvph5fn0ltH1KcnVSQVX7tc5+yz44Qt6+ReykR01czjzszzSCdmpwcqFSEe7Z3zaoU6xU1wXadtZvm23TS75jmPl0ImsY4zfThPtb2ntvBm39z9daovmxO32dRNqflHVDU4dvPM44jbcVJ5x2ncmGH2fY1He2fKzcZny7tO28x7NDfeeC9nE3j+L735fge95hfpaLp63uWcjUbdG+buIypVKBbRj+9Dx2MkV2uKE+6irn+hEnZAMlYl4bbN+9oluZV02m4jmljJJusF3Jf7JzZkb6LKNC4xcv5xhvMPcUPmT6jgsYdtvCp9Mz+KPkl70EtWpZjWVZ50v8cL3V8kF5TJWDGSjs0PavezUm9ht/9DJqae5Jda386QV0QTcFjtoos1tOoMcduhFgSsTkX5XnEPW9RaMhGb4XKVtU0xqr5msmqGN5Y8n6aIzb7yJAmibEgnOTJVIWE7VIOAo3oUnxqXRPvQaIq1gELmBrZ53yLldnGFupqUazNZrXFhNsYXJn7EJVwOwCP6fn4lcz0tUdg54bE16/CJkR/SzTqua+7m4Yk8m9NpmlzFtyYOcnlsFU+Vh5hWU7yyeT0/Gp+k20lR0wHHYxOMWf3ESHF1dC1JV/FUvkBMubRHI/SXS/gEBGja7AStMYdCLSBiKY6Up4jioJRit9rBNc6lRG2FpzVJx2LnVJ6EijChp0gSY0tTiiZX8eh4iZ54lG+X7iWp2liv1wHQzyjPS/XwcGEYX/lscDv59vTtvDj6KsqBz5gusNrNUvA8pnSFNjtBOfABOKyOs1GtxNcaWymmA4+uWJSRcpXHeJBXp17IrsIUFyTMJJMflnfz0tRmHiwMss97gN9rfw17czUua3MZmNbcUzzA/8quZcqDg/Z1XJiN8uR4mZWpKBOVgKofkI3aHC9VaHYj9FeneGj6Nm5s+k2e9o/TSycx28YLNC1Rh+9XHiarV9Cn2jmk+2nXbSgUffEE2ajFp0ZuQx8ZpvLVnURWRtHffJSpA8vXQG52PZpaSgznH8ZOvfSMr1VaL37HQtrp0s9LvYG1qQTZqGJT2ufxSRsLqASa8XJANmrREVfsnPB4ZS9867iiL2WzNhXwsaP9XJXoYaBUpRx43Fe+jTWJF3JV9ALurjzKi6KX8enBD/DK7F9wSUuUoZLmqeI4KWIMq1EyupnfuSDFkWmbzlhALYCnJhWZiCLhwN1DU7y613yYir6i7EO+CoWa2RdFL8BSELdND2dfUvE3x27j+tirsZWiGgT0JCKUfc39ld2s02tYmYzy8eP/h49ufTcHpxSdcUg7AX/w1Ad4fubN3NKX5UBBcV1HhWMll4NFi4wLj47VOOyPcmN7N0eLmo0ZqPiKQ1OaTETx4UPv58197+abUz/mBe7ldCdsvpp7mGsjlzFWqXJf7Zu8OPoqjvrjPCfZQWdc8YH97+e3ut9FLYDvVx7gbT3X0F9SZCKmH+n/DT3ILySv5lCxzHcm/5YPbngPlQBaIxpbwb8dH2CT20l73GZbbozrWlvZNjZFyorQm3T54uR/EbGTvChyPWPVMs1OlABNNQhojbp8ferrvD77am7LfYeIlaLkT/Bc+6Wsa4oRs+Hh8QKXZdPcOXkYgGtSK8lGFD0JzXeOVykEFcbUGMf97fxR1438eLTCpa1ROmOajxx/nHf1XcwXDpdYGU8QcxTXdXi4liZh+3x8r82lrRF2Tngcq+X5rVUZOmM1cjWH7w5YxGxFxdfkaz6OUkz7Ple0RblvuEhHNMa6JpsfjORZHU/xo8pOmoN2XtPVye2DQxxXu3hL13X82V8WCQ6NgWNhdTQRHJsk/1iNli98YdFzaT73XvPHXHpRP9f/R4bLUx18/PitaK1P2VxakmS/vLtV//CmlxO7qAm1thsK0+jBSUhEUB0ZiMcgGoFazXRwVKpmoIJjQ7lmHqcTYM35xgyCmVsBEWjw/NmY50MsYl4DZsDD3N6KQJu/n9Fjqh0bFQSmvGXNlgfQAdjO7LobcT3nNfUBDegAXPfkHtnGOufW/Zl1mvu4sU2WBb534vpPp1GvufWf+9zcujTWNXebGo/n7lsw65+7fWDqN/d1dv2x788+1sFsuQbfr++fZ2zH3PVb1onv0dz6NepSX7e2LNSc91836mRZqGrtxH3p2Oj6clSlcuI2naqez9xPDUEw85zecQT9yzfAF7+DaktR2z5KdRSaPvUlzrXHX/RmNl01xs9/vJOt6TT/99jpk31J2h+qKUb85q1wxUZ0Ryt6TQ88dwtcuAbasuh0EooldEsW3Z5F93Wj+1ZAUxrd24nuagPLQjdn0MkEOp1Et2TNF4PtmA9WNGLmFKeT6PbszJeFbslCrYaORtHRKIxOoCMuTOZhfBIdj5l4PGY+gHPjU0V0MgE6QKdS5nGhiI5FoVQ25Zoz4LropiZ0Jg2+P/M6CvXyQWDqHY9DcRqdiNXXnzN1qlRn45N5s/7clNkn6ZQp39Rk9lOpbJbp++hM2sTB/F+pmngiZv5Pp8zzvmf+LxTN+uvL1/G4WVatNlvnRv2KJROPx6BSQadSZpvrdSXQ5v1K1dfflDbxUtnUs7FNTU1m/yUTs/us/tqZ+jXixWmz/mQCLGX2R6FoDgKOPbNsnUqZ9zYeh/EcaqL+gwzFabNu1zVJ7rqQL5j3IeLW3+e4+RJobFOxZOoajZptTibM9oNZVmEapivmYFSumvXH6/0LybjZj69+ETgO1tZeJv9nArs1gh1fnktvEdvHilns5uF5J8Iszc8/aU3tjl24L98Kg6Po4UnUBd2Uv76TSG8MlXQp7ykQe40DY3mo1KCjGe++fdh9afRUFX+sjHPtehgcN298R5banbtxVqfRhQrBlIdzzVr00WFwHbx942aDLu0hODKGtbUPLAv/saPYWz1qDx7FK2jir3LRe46jNvdCxMV/5Cj21hq1h4+jq5rISzT6wBBqXRdEI3j37cPZ0kFt+1A9vg799ABqQzdEI/j3Po29pQPvqSG8UY/YjaD39qPWr4BYBO8He3Eu6cJ7aojyYZ/Ur0XQe4+jVrZDPErtnv24lxbxd4/g5zwiL1fo/QMzce/uPTjPWYG/YxD72g1Q9Qh2HsXa3EPtnv0oV+FcsgJv+wDOtRvA8wmeOoK1sdsM+LAV0Wv78J7ox3mBOXI24pW7DmJFwL1mFf6Ofuxr1pvyjx/C2thN9Z5DWEkL59Ie/B0D2M9dCzUP/7Ej2FtXULnnMFZC4V7Wg79r0MThhPIqpnAv7cZ/egT7qjUm/uThevwgygL3uX1QqqJWtFL+xh4ia+KobALv6QncV1wIY3l0roha2UHhP/aTuiKJak1RfWyIyCtdKFchP4Wq1Zj+2l5i62JYvc34+8awr99skrZ/DNXVQvWOp7GzDvbqLLVdo7g3OFCqoI+MoFZ3UP72PpxmG2dDK7XtI7gv22y+FI6Mola2kfvaMZpWdqO7u8C2yb6+Dz1WgCPLM5896nqoqMUmrsCeJ9uXpBl/xdou/dAf3Yh1xTp0MoEqFMFS/PktZT70f2vorjbU+CS6o3W2mWtZ6LufwHrOavPNO5yD59R76ZUFvo86MoBe2Y0qldDbD8EVG1Geb5rjw2NQrqHXrzLNvri5cT6lEkSjqFzBfNN3tEG5Yr5AHGc2PpEzR/buTnNkcU3vqipOozNpU34yj+7rNkes+re9msyhW7KowpRZflsrVGv10wptjl7pJBSKqGoN3dpsPpwR06xVhSl0pgmVqx/5+7rrpyVR8LzZ5U/kTEsCTP3icdThYxCPodtazHKS9VOfag0iLmp4FKJRs87i9Ow+KVcgFjVx10VnM2Y/1I/gM+X7h8wRtyVr6tGcMeUrFYjHUP3D5ojbWH86ZVpY9f2j+odN+Y4285416teID45AxDH7rH4qoY4Nmu2MRlDDY+iudlPG80ydRsZNPOKiBkfQLc2QTJq446D6B8166tuvuzpMS1AHMF1GHR2Algw6nUKNT5htcuyZZr86OmCum6dS5jPa0jx7WuT75nNm21CpUr33EE5vgvKOItWiRcvnv7jouTSfA7/w2/RdU6H9rx/jja2v4e8Pv/fcnrNfcdkG/dA3bkV3rzjh+cIbPk36s288bTk10H9SmdOae04rxDlmHT9m+g5yeXh0N8FgAffPP3vO67Hrht9n9cU54h/5En+6+j18+NDpk31Jztm1pU6ZtGdKdGDhiQ6S6GJZBT29qGIRgOoTY1jphY9rWEwVz6Eypnht+zvnHUG3bBljHT5EsGr1aeNqKo9ONZ1wBFfDQ5BMouMJ87w7u4NVpWx6Xd0IamjAlIlFsZ7ahe7pNk3PUhnd1wuVMkRjEARYh48Q9KxATU6C46A7O6FUQmcyYFlYR4+gmzKmmQjojs4TeorVVB5sBzU0CG4EnU5DsWialpZC5fLo5mbUvv2mmRyPmwEZfWZKohoaRLe0ogYHIR5Ht7VBPofu7AbfQ01M1Jv0Pro5a56rVtGRCGp0xJzipNNQKKDb2lGVstnWaHS2To5t6tHXZ+peKkEyiRodRTuOOSWYnEC3d5jmbrWGzmSw+vvN9kSjptMv1WROPUrT6HjCLN9S0JSByUl0R31ATqFgyuRzYDtm+0aG0C2tprOsWDSnSZOT5s1raoKpAsQTqFy9EzMRh+kSurXVLHN0xNR5cAg1Ok6wZrU59WtrRw0NYB05jl7RZd6nUhnd1WmWHY2ijh5FFafxL74I69gxdCQC6RQqlyfo6jL18Tyz/IOH0Jkm8/6Vy+jWVvMeBAGk0+Z9BNhxgKA/j7Wiieh1qwj2Di5GWpy1fCXCVx9dQ9X3cdSZb3q5JMmuPB81NICq1lC79zH26aO0vOdqeGA7+74Ca15SJv9Ujczr1sB0her9x4hct5qxzx7D8yymSxE6VhZI3niB6Twp11CtaXZ+eJLNb7BgvMjDX2viqrclzPn9RBHvUJ7iAUXmJWY0meptg6mySTjPp3bHLgDcq/rRo3nU+h7Ts1ooYY3nCHYdZ+TegM43mkuFJGOmM+vYONaaDrwfH6E66JO4rgv/yAT2ujbwAmrbh3Av6kQXSkxvmyT5i6vN+V/9cpW/cxirrwnVnKT430dJvm6zSZgn90I8Qu3Bo7gXtYNjc/RzefressL0fH/nR6iWNJX7jhF9QS/B4VHsFc0QdQn2DmN1pKg+MYadsnC2dqBHClidTeYqxbExVHua2iMDYCnca9fAxJRZZ8RGj02h0nFqO4YhMB10FMtQ3Y7Kpgh2DWC1xglGpilsr9F8y2r0gWGs9rRZ//5h7BXNVB8ZQnua6PWr0YMTWB0ZU/fBSVRXM4VvHCPWq3A3t6FzJVPeC9C5aVRXM8VvHSHW52JvaIN0HEoVyvccJ3pVO/gBU/eMk355F7pURa1ogekKlXuOEH3FRqx7HuLYl6bo/e0208G7og31wONUHhokem0faud+pr8/QOIVq8176djY37/XfIZu9lCtKbztQziX9UDEgdw0pONs/0iera8uY3U2UXtiCPdS01GrJ6ZQqSjDXxyh4+ZWtB9Q3lsleUmGYE8//sjydNDFHY8r2yb4/kDzvEf2pTlnv3S9fuib74P6ZSK8+nXWWm322mm1ao5IlUr9UlUSVSrNdLSc8Jyl0NGYOWI0WNZs3LbNssGsp37kAszRJRozR3Oof2NXzBHWsmbj1epsvFQycceBXA5i9bhlmefrce04pk6OM1s+Hp85suI4UChAJALlsvkCSKVPXn4kMrv8xvqjUXP0bizf89DpNMrzZuKUzG98EYnMH2/sbzAtj7nxWNTskzPFqzWz/CCYjdffuxPKN1oOjTiYzsj5lu/5Zp8UCvVr7qZTTmcyprXSiOdy9XENZlyFzmTMZ6BaNfuu8Rmp75OZz1gjXm96z7xnmQzUqrOfialC/Zq+c2L5Snmm5aEGh8H32fne42x8UQH72g3oHUew/+Bfzz5ZfkKDN/06rZdp/uhjq2mNKd6/7/Tn7Patt9666BX4l4//462/+9rrTO/o6Jh5M6JRrKf3mg6NQoHg3+/BWtuOKhRQtRrUqqg77kM1JUyT80t3Y63MosYmUMWi6c397J3YGdv0st75Y6yeFrP8WgV1z49Rj+1BdWSwdj4NOkAV8qh7H0HFbLhjG6Wv7iSyOYu1/1C9JzyP+u5DqJSLuucRKl/bjrspi3XwCCiNmppC3fkgKumiHnoS/xuPYq9rwzp2HAIfNVXA+tFjEHVQd22j+vUncTZksfYdAgKzbXdvM+W/u43iv+8kurkJ68BhQJv4dx9EpaOoB56g9PnHiGxtwTp8FBSofB515wOodAzr0R2opEl+Uz7A/9Sd2EMDqOYE1o+3o1JRVC5ntk/7eB+7E3voOCoTRT34pInn81i794HS+J+8C+vIUVQ2gfXQk5CMmPjT+8FSBJ++C6v/uFn+k7tR8YhZ/tMHwAL9+e9hHTyCakliPbrDDJqamsLatReURv/H3ViHjpr4YzsgXq9/PR58/vuoA0dQrSmsoRGolMm/+07ibRVUuUxw+4+weptRuTzW4DBUygy+5Yc0pUdR2qNKQa0AABq2SURBVEffsQ2rO4MaHcM6chy8GhNv/wHJ2BjK0vD9h1EtSRM/fAyUZvr/fJeomwNLwx0PoTqbUGMTWMcHQAfk3nk3ifikKf+9h1FtKdRkDuv4IPg+R/94G8lSP1ZvM/Gjx9j/WIaOTWYgz/v/c9ui59J83nnFVmIbk/zpt49zcbKNe8bv4dZbb33fqV67NOfspTL6K/egXnqZuZzSPwyFKT7whjLv+vAkakU7zsZW84N0nm8ue2UzVB4dJdY5CLaNSjjmG9ayZkYuWd1JdDSKCsrofM18SYC5pGIpM7XE8yCTMufHgNrYh86ksdZ3keytmAESTWkTtyzU1pXmMsyaTmLJqDkKpZPmcoztoFZ3oOMxVGsaZ0P9PmONkVfKmmkiqjWdxNIxM5gn22SWYzuoFa1o10VtXUm6fcIMLIHZ+Mo2dDSCWtVJIjAj8XSmfoSMRlFtTWaASCZZ3x+BaXZaFs76FlQmYUaQtTSZuGuZy4IRl8iVXZCMoeNx1OoudP1yIk0piLi4l3RC1DWDhnrbzdEWzOARy5weAGb9ybg5olrKXFa0LOw1WYi5s+tvXOJKJ8BxsFc2m0trlgXN6RPjERdnQ5tZf8RFW0mIRsm8JAuZFDriYq8x+44gMANeolFW3JJBr+8D18Va0YxWFiQT5jw/Hqf1VVlY3WW2uTVlBtVEo+iouSNs8poMtGXMwWdVm1m+pdC+GR3Y/PMZaE2b8t2Zetwy2x9x6bspgmpuQbc2k/rVDWx68AC6pMBenvHxTjxApWN0BStwlqUZf/EF+sf/8iaC9Wvr11WnTcfZ8Ii5pms7ptnd1GT+98x1cTU+bj5YYBK8udk0oSxrtkOn/uarWg3diDuOWUegzanDdGm2yVgomGZ4I97UNKcDzTqxmd+IN5rZjXg8YZrhvn9yvNFMr1ZPjj+zme77ZpuKxVOfRjTKN04Dnrn+uc3gRpMTzhxX1kxn12nLJ5Mnx2PR2SZvY/mNfXa6+Nxm/Onip1u/55ttbrzHlmWa100Z0xk7N27Xx0jMjVfN2IOT4s1Z8/lq7NN8/tTl6814NTlpvrzciCnT1GTel3IZYjHUxARq9350bycEmkffcpDL/z8HvADrtf+wuIm0ALk3/iqp61p49/taaY7An+8+x5fesGw4Pmx2vueZASfxOP7tD5pmeT6PNThkXut5ZswyoHbuRU3kTLPt4OHZD05p2vScH+tHTRVM83bvQVO+UoFyGevwUVOmWjM965UK1OqPS9OmuT88AqUSasoMgKFWM62KStk05QaHoFIxv+FVq5me79ExKBZRIyNYR4/NLrMRHxg05YeGsfoHTfl8vn6eV0GN1Nc5MmKWXyqZ5Vcqs8svlVDjE6Z8rYbK52bjg8Om/iMj5kNZqcxsn3Xk+Jnj/YOooWFT//EJU+dGvFTCOjZgyk+XTD3mxssVrGMDpk7lslm+Dkz9xsehWpstXy6b5fueGXgyPn5y+cbyG+Wfuf6iGSZrHes3t3kqFLCODZhlzo33D6ImJ82p3eCwiReLJl4qmfj4BKq+fGpmOqrK58D3T4jPlC9XZpavhkfMZ7RUMp8XHUC1ipo2v9qqxifQF/RCczPBRRdx6Tevp3RPP7p45mm4S2V0MEX18THyNY2tznzgXrLhsnrDaigUZn78jkIB++bnz3a8WBZqZNgceXRgjuqrekzzFsyotZHh2Ukq5Yppbpar9VFZrajR0ZnJC7rRbK8nohoeNn8XzRFdVWvmyD0+buKjo+bNK06bHvvGF079g6wCM/wWzzedZJ5vTiHGx81z4/W4ZaEKU6ZjrFG+UjEdWWDWWyigylWzvtFRs/7GiK163LRg1EyiqDkTMVRhymzD8Ih5ov6F1mgFnRAPzKWzRv2U58FEzvSb1PfJTEJbytTzGftsblxblvnygvo+M5OQZo6AmL4FfG+2fnPjlmW+XH3fLN+yZr8wG+vP502ZUsmcPtVqM5ODZrapEa+/Z9rzTdnhEXNUr9Xq73Uw0zGoHRs1OGTivo8KtKlTrTbT6lAzBx0f5dcnz/j+bHx4xLQMPB/ljZrwVx9AveM3zDqSKaIbk+jC8vTGDxWSTD/hUvL0vL/iuiTJrsdy3P8HB3n+Ww+hixUqj4wRvaqdBz/usHXdEMl1NnvvSbHpDxPokQL+0DTOpnY+84EEN1+zHysCjzzSzfP/xEIP5c2b3p7mO39tc8NNQwQTVT7z32v5nfdOE/RPolyb8bvLHBrMctlv+fgHJ3Eu7gJl4T3Rj72uhck7xhgZSrP+N+NmzPSmdnAdqvcfxd3SwvQDY2x7oofr3uLjHxrHXt0CUZfSnUeJXZll+v5JHtnRzbVv9vD2jOFsboeIzdT/9JO8JkPpsUkeeqSH6946cEL54reOkLgiQ+1Anm98dzW/9M4RguOTWK1JiEfJ/9dx0s9LUTtQ4H1fWc8HPzRgtqkliUrGmPjyAM0vTVN+ZIL49T3gBXg7hnE2tvLkvwas7B0nc32GyhMTxK6tx3cO42xoZe9nKrS1Fml+RZbajlHcK81lPe+pIex1LRz8QpmmdJmWX8zg7RnHvbwbgNpjAzjrWzj65RK2FdD9Swkqj40Re4EpX3tsEGdzK/u/UKW5qUTrL6SoPjVJ9Pknxnd92qeztUDLy5LUdueIPK8ef2IQd3Mbez5dpS1bpOUVTVD1UG1N/Nt7o/z6aw5iNUfY898xNv3vNHqyCOUaqiPD52+N8LpfO46KO+y8PcKWNyehUkNXaqimBP/6nihv/KWD2J0JBr7tseK32qHmmcuN2STve0eat/2vvUTWpZi8t0T2lzuhXDPXzFdm+ej7Uvz2i/cS3Zhi4odlWm7qQE9XTbw3wzf+IcmLL/WJMTsWxFrdjh7NLUUqzSsbL9Pdk8fa3Upknnb60pyzb+zR295zM2ptjxkbX29Sc2wE+jpnntONDqH6JTmVK5jZRvUpnrrpxLvOqOK06WDzfTMWuzFWG1Clcr0jJzV7Oah+lCPimvHYYDqvGs/VWwyNuPI800KYO5WzUjVlGvF4vD6gp9630Bgn3zgaxWPPKF8/V6wfXUgmzJGicQmyUpm5LKmqtZkZZjMXTUtlU6ZUNvsGZpavitOm86ux/sa5bmP7itP1zqXE7HbCmffJ3HhxGlWfwUelWl++mlnXCeuvVGfrNycOzMy0m9lnjf1TKtcvZ9ZnlVkWFKZmt6NSmelondHYX5ZVH+8fq88zqO+zQnG2no191xj7HgSoxow4150Z4z9TJ8sy2+TYpnO0VDKf0caUY1WP7z2GfvVLUePjZiTd+Bj6M99aluGyo699PZmLFVd8yOIP+/r4ve3vO+05+9Ic2dMp1Noe/CuvME/UR5xZ27+MftkmdDKFGh4yo9HmsJ54gmDL5pmRa8HqNSfE546dt57eQ7Bh42xseAhVKp12VJ4qTZuRcS2tJwbqI/RUpYzO5U6qk6qUzTX+0jTU39wT4vVvd1UpwxnKN0bD6bb2k+rVGBGoRkfMyLm58XwO3ZSZXc7c2PAQJOJmZFutesKIQqiPOotFZ0a+nTC/vRGPRMwIwdPEtWWZEXCnW38kMjOy75lDmNXwkBmV2NJ66vjc9Teem/Meq9GRk/fXnM+NGh876f1UQwMz+/CU8YF+M9LPdmb27TPjNDebEYKnWL91YD9B43P9X1/HvnID/pVXYG8+8X07V9LrA+x1nXRoi4h15gP30ty84oqN+qGHPrHoyxXip4n/zk8RuaQd/+YbsQ4dwF73u+e8DrW//nXsS3p5w28oXtatef3jH0Dr4Nwd2VWlgrVvr+nU2LkfWprQXe2ow8cB0GMFvF1juC/eAKM5aDVTGvWuo+bONpUq3o+P4Fy9Cn1kFCI2qrcN74GD2O1xiDkEI9PYl65EHxtFJWMEQ3nQGqstRTBcQGViqHiU6mND2FkXXQ2oDXvELsmgi1VUNoGKR6g9MYSdjRBM1fBzPpHntKJzJXPOnI7jbx8wg3IcRTBRxdncbs4PXRvSCVM/IJioEJR8nHUZdK5sBspkEvgHxrCSLl7/NEFZE9mQxh+axu5Lo5pT+LsGUSmXYLJKUPCJXNo+M+aadIJg7yAqWp8bsLINimVz2+J4BH//BFbaRSVddMUz142LZciVIOHiPT2JlW00/QPsdW3oqoceL6LiLv6xKVTcRsVsdNk317XLNbP9qQj+ofzM8k9Y/0QRYi7+wUlUzMbKxtClGtbKFjMcdqQAEZtgaBoVs1GtcXSubOJVHz02BREb//gUKmJhZWMEhSr2yizVx4ZweuIo2yLIVbAv6kEPTxKMlbBXZik/OIgdV9jtUbSnsS/qIdjVjzdUwd2Qobozh52xsZpM095a24G/a5Cg6OFe1En5/gEiK2Pg2uhcFfuSHvSxMXTNx2pLUbpvmOiamBk0VPaxN3cRHB5Fl32sziRT906S/Ojr0NEY7s1XwJ7DWE88AZk0Pc0v4vjk3UuRUqdlZWPojlbK3lj9zO/0J+5LcmS/tK1Vf+myX2XNVXmUq6gN+9hJxfd+0MeLrjmC2+Yyvd/DTWvcLhdvpEZQgQO7W1izaRwrrhjek6BtZZFIr4v2NNV+j/xQlParNboasOeeJi7YME601yUo+fjFgMq4RbxTY7e6+GM1vIImuiYKgcYfq1GbhEiHwko7BLkaXk4T6TXnd0HRI7/HJr3Kmylfy2uiXTYq6RAUakwfhli7xs7YBEWf2qQm0mZhJW10NaB8NCDaAXZ7FG+oYpbfaaOiFjgWxZ014n1gt8fwjpdM+RaFlTEfzOFtNq0bKzjdMbyBMrVJjduksLMOuhpQHfRx0uZvP+dRHlLEOjV22kEHZh/ZSYXT7hLkalTHNW6zws6aZC0frOIkwOmO1rc/wE4q7IwDjkX1UAUrrnBaHYKCh1cwn41Il4v2AmrDPioCbptLUPSojoKd1DjNpn+iOuhjxcDtcAmKPpVBjduksZtslGtR7a+Z8l0RU35Q47aAFbewmlwqB8pUchbpi+r13V+BQBFdYWFlI1QPlfAKisQlcagGlPZUULYmssLBbo1R2TNFraBIbjV9QZVDZTP2v8vBykapHSgyvDdJ9xVlVMzGG6riTSkiXQor6VAbrDKyL0n35WVU1MIb88xnpg3sjEO1v0ZhMELbp29CxxNYR4+gnj6APjSM2rqK1p+/DU3A5NRTi55Tp+N/6vfh6gt58fP38XtrEtzy2F8R6Nq5O7Lbvc1sfHsX/rU3ARCtn++9/M7vE1z9y+imDMnGrLY5ldiyby+6uxsch545578KiAIdkxPo5iwK2PKGYzPnzxZg53NEStMz52s2c298DLbv4VSr5vy4XmbuGa4VBGSnp2bqNFO+0d9Qq5LO5WbO4RrxmXP6ICCRz6Gbs+i55eecq6bq23y6eGd9++bGZ2aY+R7ROee8NpDK58yIu3gCFQRE55xzW0B8Km9mvdXPteeecVtAtD5jr7FPIqeKg+mT8D0ic9ZvAfE566f+Hs2NJ/I5sG10MnXK5cfnrF/X49E559nxOefUGnCByJzn4nM+Q0EjXt+H1OvfiGvM56xnTtytlHHm9EO4QE8+h06lwbJwi1M4ydlbg0eAtskJs78rZfb//oOse3svT93mcuEb+rnMfglHrSNMcu6SnbK55HtTbxrXqqHOMPNtaTroHAf/2hfM/l3fof4N188+lzr5/u7Butn7x9Nx8g8DNN4k4KSOMt2UMaOhTsd20PEzbK5lnbJOM51WbuSkzhqY3TZzz7zsSfG5nVKnXP7c+CnKNxLpVPP3T+hcsk5uvp1yfc82Pt/6T1V+vvgp1j+3Q+1U5ec+d8ryc/bhvPHoKT5jc5efPPk3AGbKj4/TvTpP8PABLvpts560HWG0tu+kMkspyFWwi9OsT5VxrYAz3YhOfhFGiGdBd3YR7bKZeqqKt2cMHJttwf2MFx4/p/XYd3cS/wc7KPo2mUgVi3N8ZFelMvYjj6K7OlBP7UEfGoGffy5q9368R44ytTcg0aVxb7kKtesgOtBw0Vp4eDe6WMUfKmNnI1gv3Ip/91NYmShctRn/m49w7MEYEcen6wYLdc0Wgu89ib0yS237sCmzvoPv/VXAiz+QhIjDtneOcuUt0+QfKJLo0bhX9XLf3/q84P1piDgc+ZtD9L7YZ/iHmrZLPJyrV7HtL4tc9a40NKUY/bsdZC+Bqad90s+JYF3Ux7F/Ok7vm1dAU4rpzz5ObFOcqccrJLe42Ju7+ee/cPnff2sm5BQ+9RSJ9Q65JzWZ51jYF/Xw4F+VeO6fRaCjhcK/PEGsV3F4W4oLXlTGvmoNOz4wzNa3NkFHC+UvPUp0fYrxH1RofetWKJbY+6FB1r8pg799gOpgjdjWNMN3Vun8040wXeGBW/M8708cvCf6qY36RDcm2fsNl43v7oFKlXveM811f6Lxdg6bTskNaQ7+J6x5Wy94Pk9+cIyL3xTB2z6ErgY4m1oY+No0K96+ESpVdn9ggE1vSuE93o834RO9NMueL8Cm9/dB1WPbu8e46i023vYh/KmAyMUtHL6twup3XADVGtveO8FVb3Xwnhw069+SofxEjvhNWwgePcBdt7Vz+apBMhdqnBsuRD99lNIDYyRu2UqwbT/33d7CxRcMkVyjcW+8FP34PnL3Fmi+ZTXBngEevb2JrRcP4bbaOD9/ERzsZ/e/1dj0rm78+/ey53tp1l81YW5A+rrnwMAIhz6ZY/Wf9uLdu5ejDyXouXiKoKKJ3XwxHBnmwGemWfPWDrz7D/Kuz63lLx/YDFGL5CZF5VAVe02VkamdS5FOZ2QpDYHm6LTLmrQ+45FdLr0JcZbUQD9W/yD+5ZcBkP+1z5B9dTvWzX9/zuvif+J34UWX88Wbj3B15wgX3vVFKt7kOZwIA6f+YYNa1XRIBYGZmPCM16j6hBeCwNzuqf64sTw1ZcZgU6uiilMnli1OzTynKuX63UC9mTIqn0NNmtsLnRSvL3umTrXqyfHilImDqUOjTvU6z8Qb5euvU8Wp2eXX139CfL7lN7apNOdXQuvl1VT+xHhjXzXi+dwJy5/Zt/UbeSw4/oz1z8Sn8ifGG/MB5sZPUb9TlZ9Zdz5n4nP2zQnxyQmzrLnxxj71PROfs8/N5Bxv5j1V+dzse9aIzy0/Pmaer1XNsipl8684Zf4fGoBkkmDThpn90fyX15spwstAdTWjO9op+YqI43Om385bsuvs9rYfE6zqM+Pai9Nm+OHBI+b20fE4jE9Ad5cZ+lqtomNRrMNHzY88WBZqIkfQ12NmHdV/fcQ63m9uO+x7qJFxs/z65AU1OobyPIIVXWbCRMpMp1T5PKRSZtaV70Nn1cTrd7JRk5PQVJqZCRX0rJgdymtZplw2Y2bjlUpm+Y1JOcoys73qcSoV6O46dfnClBne2bOiPjxYmVFcwyPQam5FrQpTZv21mhmyaTuooSFoazU3/Wg2Py6opotmvvWguZXzSfFSCR2LmrjrmvjUFNR/4EFNmymmJ5QvTp8cHzZjCOhoM/WvD18+ZfmfMA6A7WAdPYbOZlBuBEbHzP5qfPk14i1ZiJgp0/SsmP1CsKyZ8kRjZt93d5lYfbirdfS4uV9AMmkmC3V2zk6Zdl3zGUsmzP3mxsfR7e1mola1ho645oh+6aVmdfv2gmMTrF6DPTDIpuzNHK88RmF676Lm0xl1tKBTTezIWbwqUT3jb7RLM16In5D94EMwUeCW37TZXx3lx7lz99n3H/kIwSWXsPult7N6/Tjtn/w2JW/s3F1nFyJM/Csvx7rtv/m7FxTYPdjGP+5+G/3BBFoF2NohIMDCwlceARpb22h1ht/vOxv1H7BYd8k4kQ1pznkzXogwKL/pkyRf2IG+6kJUOk7XL1tk7jvOb3urcK36KUv9tY328/y/Rn92VLWGmp7Cffur0UGAevNXTvvapbv09u272PfRcdb9WTe6PYvac5j3vSPNez9n7tPm3f4I3/zOSl7zsRZ0MoF/+4PknlK0vP0ylOdx8D1Ps2LLFJFbzAyj4Q8+SfOqCtHXXga+x853H2PjDVNYL7vUTD196gD+oTzODVvMjSaODKOHp7DWd5jzmqePmjnZv7jR3ENteJzqA/3mPm2rumH/MfLfHaXpV1abe9jlpih98wDx67rhghVweICxL4/Q+sY+aGmG8UkTf0kP9HXB/uPkvjVM5ldWQTYNuSnytx2i6Rc60Wt7UfuPMfqVUdp+tQO6WmG6wtF/OEbvzXHYegHq2BB7Pppn4+8lzPJKZfb+5XHWvc5BbVoFoxN4jxzFubATOlqgWqPyP3uIXNyC2rIaBsdM/OKumXj123twtzTXy0/i7xow8+w7zMCQ2vd246xMoy68AMZzZhx+SxK1sgMcG+/7u7A7E6iL10B+imBPP1ZbCla0gaXwvrcbe0US9Zx1MD5JsMPciJGuFgC8e5825U8Xv2cPdne9vKUIfriDv/74St7xcQudSRPc+QTfvb2Ll/+zWV/wo5287R/6+NAnAnRbFv2jHfzJh3v5+/+IgbLQuw/zLx9p5ff+NjB9Qw/v4Y3v6eAzX3LMVNbDg9z9jw4vepdrfjz00ad58LMJnvf+jJkKe7CfBz+KuSy6oh395H4e/WyEy99tfnlYHxrk/v/ncM3HVqHvfJzP/Wg92W0+l7c/gh9YbPjPlxO7ephXPPQk2gtgCU6RnylYv3bewVENS3LOrpQaAQ4v+oKFEPNZpbU+5aWBJUl2IcRPHxkuK0RISLILERKS7EKEhCR7CCilWpVSj9f/DSqljtcfTymlPrbc9RPnhnTQhYxS6lZgSmv94eWuizi35MgeYkqp65RS/11/fKtS6rNKqR8qpQ4rpV6jlPqQUmq7Uuo7Sim3/rrLlVI/UEo9opS6Qym1PLdVFWdNkl3MtRa4HrgR+Hfgbq31RUAJeEU94f8ZuElrfTnwb8AHl6uy4uzIcFkx17e11jWl1HbMbe6+U39+O7Aa2AhcCNypzE0SbGBgGeopngVJdjFXBUBrHSilanq2QyfAfFYUsENr/bzlqqB49qQZL87GHqBdKfU8AKWUq5Tausx1EgskyS4WTGtdBW4C/kYp9QTwOHDN8tZKLJRcehMiJOTILkRISLILERKS7EKEhCS7ECEhyS5ESEiyCxESkuxChMT/Dyuwpzu/RzivAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x442.347 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('Original Audio')\n",
        "play(audio)\n",
        "print('Resynthesized Audio')\n",
        "play(audio_gen)\n",
        "print('Filtered Noise Audio')\n",
        "audio_noise = controls['noise']['signal']\n",
        "play(audio_noise)\n",
        "\n",
        "specplot(audio)\n",
        "specplot(audio_gen)\n",
        "specplot(audio_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVhoLzV-ZYav"
      },
      "outputs": [],
      "source": [
        "batch_idx = 0\n",
        "get = lambda key: ddsp.core.nested_lookup(key, controls)[batch_idx]\n",
        "\n",
        "amps = get('harmonic/controls/amplitudes')\n",
        "harmonic_distribution = get('harmonic/controls/harmonic_distribution')\n",
        "noise_magnitudes = get('noise/controls/magnitudes')\n",
        "f0_hz = get('f0_hz')\n",
        "loudness = get('loudness_db')\n",
        "\n",
        "audio_noise = get('noise/signal')\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "f.suptitle('Input Features', fontsize=16)\n",
        "ax[0].plot(loudness)\n",
        "ax[0].set_ylabel('Loudness')\n",
        "ax[1].plot(f0_hz)\n",
        "ax[1].set_ylabel('F0_Hz')\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
        "f.suptitle('Synth Params', fontsize=16)\n",
        "ax[0].semilogy(amps)\n",
        "ax[0].set_ylabel('Amps')\n",
        "ax[0].set_ylim(1e-5, 2)\n",
        "# ax[0].semilogy(harmonic_distribution)\n",
        "ax[1].matshow(np.rot90(np.log10(harmonic_distribution + 1e-6)),\n",
        "              cmap=plt.cm.magma, \n",
        "              aspect='auto')\n",
        "ax[1].set_ylabel('Harmonic Distribution')\n",
        "ax[1].set_xticks([])\n",
        "_ = ax[1].set_yticks([])\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
        "# f.suptitle('Filtered Noise Params', fontsize=16)\n",
        "ax.matshow(np.rot90(np.log10(noise_magnitudes + 1e-6)), \n",
        "           cmap=plt.cm.magma, \n",
        "           aspect='auto')\n",
        "ax.set_ylabel('Filtered Noise Magnitudes')\n",
        "ax.set_xticks([])\n",
        "_ = ax.set_yticks([])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hMqWDc_m6rUC",
        "ZFIqwYGbZ-df",
        "khYj8yiMDxGL",
        "acGO0ifg0I3k",
        "Op0V8onI0VUK",
        "EWZQXFLehCU0",
        "uAZgDMV9hGyp",
        "MnnxpYbRrPrp",
        "IGvCE5BbrWTU",
        "RFEqt6e1DsqG",
        "2cj220vSF8_Y"
      ],
      "name": "3_training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}